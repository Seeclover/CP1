{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7311385b-16ac-4569-b415-2c4e2a392bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from utils import save_predictions_to_csv, standardize_data, calculate_auc_score, compare_auc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b767c7f0-7ddf-4c19-bdff-7ee192a3e55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset_1\n",
      "X_train shape: (444, 20)\n",
      "y_train shape: (444, 1)\n",
      "X_test shape: (296, 20)\n",
      "------------------------------\n",
      "Dataset: Dataset_10\n",
      "X_train shape: (467, 11)\n",
      "y_train shape: (467, 1)\n",
      "X_test shape: (312, 11)\n",
      "------------------------------\n",
      "Dataset: Dataset_11\n",
      "X_train shape: (58, 62)\n",
      "y_train shape: (58, 1)\n",
      "X_test shape: (39, 62)\n",
      "------------------------------\n",
      "Dataset: Dataset_12\n",
      "X_train shape: (154, 5)\n",
      "y_train shape: (154, 1)\n",
      "X_test shape: (104, 5)\n",
      "------------------------------\n",
      "Dataset: Dataset_13\n",
      "X_train shape: (181, 54)\n",
      "y_train shape: (181, 1)\n",
      "X_test shape: (122, 54)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Load datasets\n",
    "dataset_names=[]\n",
    "X_trains=[]\n",
    "y_trains=[]\n",
    "X_tests=[]\n",
    "for folder_name in os.listdir(\"./Competition_data\"):\n",
    "    # print(folder_name)\n",
    "    dataset_names.append(folder_name)\n",
    "    X_trains.append(pd.read_csv(f\"./Competition_data/{folder_name}/X_train.csv\",header=0))\n",
    "    y_trains.append(pd.read_csv(f\"./Competition_data/{folder_name}/y_train.csv\",header=0))\n",
    "    X_tests.append(pd.read_csv(f\"./Competition_data/{folder_name}/X_test.csv\",header=0))\n",
    "\n",
    "\n",
    "for i in range(min(5, len(dataset_names))):\n",
    "    print(f\"Dataset: {dataset_names[i]}\")\n",
    "    print(f\"X_train shape: {X_trains[i].shape}\")\n",
    "    print(f\"y_train shape: {y_trains[i].shape}\")\n",
    "    print(f\"X_test shape: {X_tests[i].shape}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f5b325-c761-4be1-ae61-f55839ddb262",
   "metadata": {},
   "source": [
    "## Put your code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07fe25ca-3dbc-4562-b06a-b5f36a973a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_important_features(X_train, y_train, n_features=10):\n",
    "    \"\"\"\n",
    "    Select the most important features using RandomForest feature importances.\n",
    "    \n",
    "    Parameters:\n",
    "    X_train : pd.DataFrame\n",
    "        The training features.\n",
    "    y_train : pd.Series or array-like\n",
    "        The training labels.\n",
    "    n_features : int, optional\n",
    "        The number of top important features to select (default is 10).\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        A DataFrame containing only the selected important features.\n",
    "    list\n",
    "        The list of selected feature names.\n",
    "    \"\"\"\n",
    "    # Train a RandomForest model to get feature importances\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get feature importances\n",
    "    importances = model.feature_importances_\n",
    "    feature_indices = importances.argsort()[-n_features:]  # Select top n features\n",
    "    \n",
    "    # Return the DataFrame with selected important features\n",
    "    selected_features = X_train.columns[feature_indices]\n",
    "    return X_train[selected_features], selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc8ad1d5-b256-4a4d-ae32-b46e2ebe9543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: Dataset_1\n",
      "Dataset: Dataset_1 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_10\n",
      "Dataset: Dataset_10 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_11\n",
      "Dataset: Dataset_11 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_12\n",
      "Dataset: Dataset_12 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_13\n",
      "Dataset: Dataset_13 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_14\n",
      "Dataset: Dataset_14 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_15\n",
      "Dataset: Dataset_15 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_16\n",
      "Dataset: Dataset_16 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_17\n",
      "Dataset: Dataset_17 - AUC after Feature Selection: 0.9999\n",
      "Processing dataset: Dataset_18\n",
      "Dataset: Dataset_18 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_19\n",
      "Dataset: Dataset_19 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_2\n",
      "Dataset: Dataset_2 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_20\n",
      "Dataset: Dataset_20 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_21\n",
      "Dataset: Dataset_21 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_22\n",
      "Dataset: Dataset_22 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_23\n",
      "Dataset: Dataset_23 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_24\n",
      "Dataset: Dataset_24 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_25\n",
      "Dataset: Dataset_25 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_26\n",
      "Dataset: Dataset_26 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_27\n",
      "Dataset: Dataset_27 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_28\n",
      "Dataset: Dataset_28 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_29\n",
      "Dataset: Dataset_29 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_3\n",
      "Dataset: Dataset_3 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_30\n",
      "Dataset: Dataset_30 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_31\n",
      "Dataset: Dataset_31 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_32\n",
      "Dataset: Dataset_32 - AUC after Feature Selection: 0.9653\n",
      "Processing dataset: Dataset_33\n",
      "Dataset: Dataset_33 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_34\n",
      "Dataset: Dataset_34 - AUC after Feature Selection: 0.9997\n",
      "Processing dataset: Dataset_35\n",
      "Dataset: Dataset_35 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_36\n",
      "Dataset: Dataset_36 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_37\n",
      "Dataset: Dataset_37 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_38\n",
      "Dataset: Dataset_38 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_39\n",
      "Dataset: Dataset_39 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_4\n",
      "Dataset: Dataset_4 - AUC after Feature Selection: 0.9999\n",
      "Processing dataset: Dataset_40\n",
      "Dataset: Dataset_40 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_41\n",
      "Dataset: Dataset_41 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_42\n",
      "Dataset: Dataset_42 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_43\n",
      "Dataset: Dataset_43 - AUC after Feature Selection: 0.9653\n",
      "Processing dataset: Dataset_44\n",
      "Dataset: Dataset_44 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_45\n",
      "Dataset: Dataset_45 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_46\n",
      "Dataset: Dataset_46 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_47\n",
      "Dataset: Dataset_47 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_48\n",
      "Dataset: Dataset_48 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_49\n",
      "Dataset: Dataset_49 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_5\n",
      "Dataset: Dataset_5 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_6\n",
      "Dataset: Dataset_6 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_7\n",
      "Dataset: Dataset_7 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_8\n",
      "Dataset: Dataset_8 - AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_9\n",
      "Dataset: Dataset_9 - AUC after Feature Selection: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#RF test\n",
    "from models import train_random_forest\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    print(f\"Processing dataset: {dataset_names[i]}\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_trains[i])\n",
    "    X_test_scaled = scaler.transform(X_tests[i])\n",
    "    \n",
    "    X_train_df = pd.DataFrame(X_train_scaled, columns=X_trains[i].columns)\n",
    "    X_test_df = pd.DataFrame(X_test_scaled, columns=X_tests[i].columns)\n",
    "    \n",
    "    X_train_selected, selected_features = select_important_features(X_train_df, y_trains[i].values.ravel(), n_features=10)\n",
    "    \n",
    "    X_test_selected = X_test_df[selected_features]\n",
    "    \n",
    "    model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model_rf.fit(X_train_selected, y_trains[i].values.ravel())\n",
    "    \n",
    "    y_prob_train = model_rf.predict_proba(X_train_selected)[:, 1]\n",
    "    auc_score = roc_auc_score(y_trains[i], y_prob_train)\n",
    "    print(f\"Dataset: {dataset_names[i]} - AUC after Feature Selection: {auc_score:.4f}\")\n",
    "    \n",
    "    y_prob_test = model_rf.predict_proba(X_test_selected)[:, 1]\n",
    "    \n",
    "    save_predictions_to_csv(y_prob_test, dataset_names[i], folder_path='./Competition_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8b41ad8-340b-4a1c-b07a-d64060ebee09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset: Dataset_1\n",
      "Dataset: Dataset_1 - SVM AUC after Feature Selection: 0.9012\n",
      "Processing dataset: Dataset_10\n",
      "Dataset: Dataset_10 - SVM AUC after Feature Selection: 0.8750\n",
      "Processing dataset: Dataset_11\n",
      "Dataset: Dataset_11 - SVM AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_12\n",
      "Dataset: Dataset_12 - SVM AUC after Feature Selection: 0.9420\n",
      "Processing dataset: Dataset_13\n",
      "Dataset: Dataset_13 - SVM AUC after Feature Selection: 0.9677\n",
      "Processing dataset: Dataset_14\n",
      "Dataset: Dataset_14 - SVM AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_15\n",
      "Dataset: Dataset_15 - SVM AUC after Feature Selection: 0.8764\n",
      "Processing dataset: Dataset_16\n",
      "Dataset: Dataset_16 - SVM AUC after Feature Selection: 0.9978\n",
      "Processing dataset: Dataset_17\n",
      "Dataset: Dataset_17 - SVM AUC after Feature Selection: 0.9779\n",
      "Processing dataset: Dataset_18\n",
      "Dataset: Dataset_18 - SVM AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_19\n",
      "Dataset: Dataset_19 - SVM AUC after Feature Selection: 0.9923\n",
      "Processing dataset: Dataset_2\n",
      "Dataset: Dataset_2 - SVM AUC after Feature Selection: 0.9978\n",
      "Processing dataset: Dataset_20\n",
      "Dataset: Dataset_20 - SVM AUC after Feature Selection: 0.9887\n",
      "Processing dataset: Dataset_21\n",
      "Dataset: Dataset_21 - SVM AUC after Feature Selection: 0.9727\n",
      "Processing dataset: Dataset_22\n",
      "Dataset: Dataset_22 - SVM AUC after Feature Selection: 0.9337\n",
      "Processing dataset: Dataset_23\n",
      "Dataset: Dataset_23 - SVM AUC after Feature Selection: 0.9637\n",
      "Processing dataset: Dataset_24\n",
      "Dataset: Dataset_24 - SVM AUC after Feature Selection: 0.8413\n",
      "Processing dataset: Dataset_25\n",
      "Dataset: Dataset_25 - SVM AUC after Feature Selection: 0.9865\n",
      "Processing dataset: Dataset_26\n",
      "Dataset: Dataset_26 - SVM AUC after Feature Selection: 0.9470\n",
      "Processing dataset: Dataset_27\n",
      "Dataset: Dataset_27 - SVM AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_28\n",
      "Dataset: Dataset_28 - SVM AUC after Feature Selection: 0.9200\n",
      "Processing dataset: Dataset_29\n",
      "Dataset: Dataset_29 - SVM AUC after Feature Selection: 0.9742\n",
      "Processing dataset: Dataset_3\n",
      "Dataset: Dataset_3 - SVM AUC after Feature Selection: 0.9849\n",
      "Processing dataset: Dataset_30\n",
      "Dataset: Dataset_30 - SVM AUC after Feature Selection: 0.8617\n",
      "Processing dataset: Dataset_31\n",
      "Dataset: Dataset_31 - SVM AUC after Feature Selection: 0.9599\n",
      "Processing dataset: Dataset_32\n",
      "Dataset: Dataset_32 - SVM AUC after Feature Selection: 0.2811\n",
      "Processing dataset: Dataset_33\n",
      "Dataset: Dataset_33 - SVM AUC after Feature Selection: 0.9999\n",
      "Processing dataset: Dataset_34\n",
      "Dataset: Dataset_34 - SVM AUC after Feature Selection: 0.8951\n",
      "Processing dataset: Dataset_35\n",
      "Dataset: Dataset_35 - SVM AUC after Feature Selection: 0.9211\n",
      "Processing dataset: Dataset_36\n",
      "Dataset: Dataset_36 - SVM AUC after Feature Selection: 0.9994\n",
      "Processing dataset: Dataset_37\n",
      "Dataset: Dataset_37 - SVM AUC after Feature Selection: 0.9652\n",
      "Processing dataset: Dataset_38\n",
      "Dataset: Dataset_38 - SVM AUC after Feature Selection: 0.8794\n",
      "Processing dataset: Dataset_39\n",
      "Dataset: Dataset_39 - SVM AUC after Feature Selection: 0.9993\n",
      "Processing dataset: Dataset_4\n",
      "Dataset: Dataset_4 - SVM AUC after Feature Selection: 0.9899\n",
      "Processing dataset: Dataset_40\n",
      "Dataset: Dataset_40 - SVM AUC after Feature Selection: 0.9211\n",
      "Processing dataset: Dataset_41\n",
      "Dataset: Dataset_41 - SVM AUC after Feature Selection: 0.9933\n",
      "Processing dataset: Dataset_42\n",
      "Dataset: Dataset_42 - SVM AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_43\n",
      "Dataset: Dataset_43 - SVM AUC after Feature Selection: 0.2811\n",
      "Processing dataset: Dataset_44\n",
      "Dataset: Dataset_44 - SVM AUC after Feature Selection: 1.0000\n",
      "Processing dataset: Dataset_45\n",
      "Dataset: Dataset_45 - SVM AUC after Feature Selection: 0.9994\n",
      "Processing dataset: Dataset_46\n",
      "Dataset: Dataset_46 - SVM AUC after Feature Selection: 0.9549\n",
      "Processing dataset: Dataset_47\n",
      "Dataset: Dataset_47 - SVM AUC after Feature Selection: 0.9837\n",
      "Processing dataset: Dataset_48\n",
      "Dataset: Dataset_48 - SVM AUC after Feature Selection: 0.9972\n",
      "Processing dataset: Dataset_49\n",
      "Dataset: Dataset_49 - SVM AUC after Feature Selection: 0.9665\n",
      "Processing dataset: Dataset_5\n",
      "Dataset: Dataset_5 - SVM AUC after Feature Selection: 0.9983\n",
      "Processing dataset: Dataset_6\n",
      "Dataset: Dataset_6 - SVM AUC after Feature Selection: 0.9984\n",
      "Processing dataset: Dataset_7\n",
      "Dataset: Dataset_7 - SVM AUC after Feature Selection: 0.9997\n",
      "Processing dataset: Dataset_8\n",
      "Dataset: Dataset_8 - SVM AUC after Feature Selection: 0.9663\n",
      "Processing dataset: Dataset_9\n",
      "Dataset: Dataset_9 - SVM AUC after Feature Selection: 0.9085\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    print(f\"Processing dataset: {dataset_names[i]}\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_trains[i])\n",
    "    X_test_scaled = scaler.transform(X_tests[i])\n",
    "    \n",
    "    X_train_df = pd.DataFrame(X_train_scaled, columns=X_trains[i].columns)\n",
    "    X_test_df = pd.DataFrame(X_test_scaled, columns=X_tests[i].columns)\n",
    "    \n",
    "    X_train_selected, selected_features = select_important_features(X_train_df, y_trains[i].values.ravel(), n_features=10)\n",
    "    \n",
    "    X_test_selected = X_test_df[selected_features]\n",
    "\n",
    "    model_svm = SVC(kernel='rbf', probability=True, random_state=42)\n",
    "    model_svm.fit(X_train_selected, y_trains[i].values.ravel())\n",
    "    \n",
    "    y_prob_train = model_svm.predict_proba(X_train_selected)[:, 1]\n",
    "    auc_score = roc_auc_score(y_trains[i], y_prob_train)\n",
    "    print(f\"Dataset: {dataset_names[i]} - SVM AUC after Feature Selection: {auc_score:.4f}\")\n",
    "    \n",
    "    y_prob_test = model_svm.predict_proba(X_test_selected)[:, 1]\n",
    "    \n",
    "    save_predictions_to_csv(y_prob_test, dataset_names[i], folder_path='./Competition_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c42bddc-680c-43dd-a3de-8d3229ccd52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each dataset and save the results as binary (0/1)\n",
    "for i, dataset_name in enumerate(dataset_names):\n",
    "    # Standardize the test set using the previously fitted scaler\n",
    "    X_test_standardized = standardize_data(X_trains[i], X_tests[i])[1]\n",
    "    \n",
    "    # Make predictions on the test set and convert to binary (0 or 1)\n",
    "    y_prob = svm_models[i].predict_proba(X_test_standardized)[:, 1] \n",
    "    \n",
    "    # Save predictions to CSV\n",
    "    save_predictions_to_csv(y_prob, dataset_name, folder_path='./Competition_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3b511a3-fc78-4e1d-96b4-e02e65f0b86e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing AUC Scores between SVM(Model 1) and Random Forest(Model 2):\n",
      "Dataset: Dataset_1 - AUC Difference: 0.0204 (Model 1 - Model 2)\n",
      "Dataset: Dataset_10 - AUC Difference: -0.0765 (Model 1 - Model 2)\n",
      "Dataset: Dataset_11 - AUC Difference: 0.0000 (Model 1 - Model 2)\n",
      "Dataset: Dataset_12 - AUC Difference: -0.1381 (Model 1 - Model 2)\n",
      "Dataset: Dataset_13 - AUC Difference: -0.1867 (Model 1 - Model 2)\n",
      "Dataset: Dataset_14 - AUC Difference: -0.1733 (Model 1 - Model 2)\n",
      "Dataset: Dataset_15 - AUC Difference: -0.0887 (Model 1 - Model 2)\n",
      "Dataset: Dataset_16 - AUC Difference: -0.0024 (Model 1 - Model 2)\n",
      "Dataset: Dataset_17 - AUC Difference: -0.2519 (Model 1 - Model 2)\n",
      "Dataset: Dataset_18 - AUC Difference: 0.0000 (Model 1 - Model 2)\n",
      "Dataset: Dataset_19 - AUC Difference: -0.1914 (Model 1 - Model 2)\n",
      "Dataset: Dataset_2 - AUC Difference: -0.0024 (Model 1 - Model 2)\n",
      "Dataset: Dataset_20 - AUC Difference: -0.0606 (Model 1 - Model 2)\n",
      "Dataset: Dataset_21 - AUC Difference: -0.3304 (Model 1 - Model 2)\n",
      "Dataset: Dataset_22 - AUC Difference: -0.0850 (Model 1 - Model 2)\n",
      "Dataset: Dataset_23 - AUC Difference: -0.0904 (Model 1 - Model 2)\n",
      "Dataset: Dataset_24 - AUC Difference: -0.0971 (Model 1 - Model 2)\n",
      "Dataset: Dataset_25 - AUC Difference: -0.0926 (Model 1 - Model 2)\n",
      "Dataset: Dataset_26 - AUC Difference: -0.2846 (Model 1 - Model 2)\n",
      "Dataset: Dataset_27 - AUC Difference: -0.0400 (Model 1 - Model 2)\n",
      "Dataset: Dataset_28 - AUC Difference: -0.2492 (Model 1 - Model 2)\n",
      "Dataset: Dataset_29 - AUC Difference: -0.2703 (Model 1 - Model 2)\n",
      "Dataset: Dataset_3 - AUC Difference: -0.5000 (Model 1 - Model 2)\n",
      "Dataset: Dataset_30 - AUC Difference: -0.1338 (Model 1 - Model 2)\n",
      "Dataset: Dataset_31 - AUC Difference: -0.3333 (Model 1 - Model 2)\n",
      "Dataset: Dataset_32 - AUC Difference: 0.0337 (Model 1 - Model 2)\n",
      "Dataset: Dataset_33 - AUC Difference: -0.0332 (Model 1 - Model 2)\n",
      "Dataset: Dataset_34 - AUC Difference: -0.2271 (Model 1 - Model 2)\n",
      "Dataset: Dataset_35 - AUC Difference: -0.1129 (Model 1 - Model 2)\n",
      "Dataset: Dataset_36 - AUC Difference: -0.2234 (Model 1 - Model 2)\n",
      "Dataset: Dataset_37 - AUC Difference: -0.2546 (Model 1 - Model 2)\n",
      "Dataset: Dataset_38 - AUC Difference: -0.3290 (Model 1 - Model 2)\n",
      "Dataset: Dataset_39 - AUC Difference: -0.1461 (Model 1 - Model 2)\n",
      "Dataset: Dataset_4 - AUC Difference: -0.3980 (Model 1 - Model 2)\n",
      "Dataset: Dataset_40 - AUC Difference: -0.1129 (Model 1 - Model 2)\n",
      "Dataset: Dataset_41 - AUC Difference: -0.1816 (Model 1 - Model 2)\n",
      "Dataset: Dataset_42 - AUC Difference: -0.5175 (Model 1 - Model 2)\n",
      "Dataset: Dataset_43 - AUC Difference: 0.0337 (Model 1 - Model 2)\n",
      "Dataset: Dataset_44 - AUC Difference: 0.0000 (Model 1 - Model 2)\n",
      "Dataset: Dataset_45 - AUC Difference: -0.1000 (Model 1 - Model 2)\n",
      "Dataset: Dataset_46 - AUC Difference: -0.1619 (Model 1 - Model 2)\n",
      "Dataset: Dataset_47 - AUC Difference: -0.0536 (Model 1 - Model 2)\n",
      "Dataset: Dataset_48 - AUC Difference: -0.3491 (Model 1 - Model 2)\n",
      "Dataset: Dataset_49 - AUC Difference: -0.0376 (Model 1 - Model 2)\n",
      "Dataset: Dataset_5 - AUC Difference: 0.1467 (Model 1 - Model 2)\n",
      "Dataset: Dataset_6 - AUC Difference: -0.0321 (Model 1 - Model 2)\n",
      "Dataset: Dataset_7 - AUC Difference: -0.0672 (Model 1 - Model 2)\n",
      "Dataset: Dataset_8 - AUC Difference: -0.3073 (Model 1 - Model 2)\n",
      "Dataset: Dataset_9 - AUC Difference: -0.2500 (Model 1 - Model 2)\n"
     ]
    }
   ],
   "source": [
    "# Compare AUC scores between SVM and Random Forest\n",
    "print(\"\\nComparing AUC Scores between SVM(Model 1) and Random Forest(Model 2):\")\n",
    "auc_differences = compare_auc_scores(svm_auc_scores, rf_auc_scores, dataset_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "601c35b5-ac5b-4911-a18a-957e0e40631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\78963\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset_1 - MLP AUC Score: 0.7286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\78963\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset_10 - MLP AUC Score: 0.7506\n",
      "Dataset: Dataset_11 - MLP AUC Score: 0.3714\n",
      "Dataset: Dataset_12 - MLP AUC Score: 0.9762\n",
      "Dataset: Dataset_13 - MLP AUC Score: 0.9100\n",
      "Dataset: Dataset_14 - MLP AUC Score: 0.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\78963\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset_15 - MLP AUC Score: 0.6733\n",
      "Dataset: Dataset_16 - MLP AUC Score: 0.9995\n",
      "Dataset: Dataset_17 - MLP AUC Score: 0.9111\n",
      "Dataset: Dataset_18 - MLP AUC Score: 1.0000\n",
      "Dataset: Dataset_19 - MLP AUC Score: 0.9912\n",
      "Dataset: Dataset_2 - MLP AUC Score: 0.9995\n",
      "Dataset: Dataset_20 - MLP AUC Score: 0.9212\n",
      "Dataset: Dataset_21 - MLP AUC Score: 0.9604\n",
      "Dataset: Dataset_22 - MLP AUC Score: 0.7908\n",
      "Dataset: Dataset_23 - MLP AUC Score: 0.9140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\78963\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset_24 - MLP AUC Score: 0.5964\n",
      "Dataset: Dataset_25 - MLP AUC Score: 0.9074\n",
      "Dataset: Dataset_26 - MLP AUC Score: 0.7769\n",
      "Dataset: Dataset_27 - MLP AUC Score: 1.0000\n",
      "Dataset: Dataset_28 - MLP AUC Score: 0.8296\n",
      "Dataset: Dataset_29 - MLP AUC Score: 0.9211\n",
      "Dataset: Dataset_3 - MLP AUC Score: 0.8125\n",
      "Dataset: Dataset_30 - MLP AUC Score: 0.6699\n",
      "Dataset: Dataset_31 - MLP AUC Score: 0.7879\n",
      "Dataset: Dataset_32 - MLP AUC Score: 0.8099\n",
      "Dataset: Dataset_33 - MLP AUC Score: 1.0000\n",
      "Dataset: Dataset_34 - MLP AUC Score: 0.8371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\78963\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset_35 - MLP AUC Score: 0.8220\n",
      "Dataset: Dataset_36 - MLP AUC Score: 0.9121\n",
      "Dataset: Dataset_37 - MLP AUC Score: 0.8117\n",
      "Dataset: Dataset_38 - MLP AUC Score: 0.7510\n",
      "Dataset: Dataset_39 - MLP AUC Score: 0.9916\n",
      "Dataset: Dataset_4 - MLP AUC Score: 0.6684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\78963\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset_40 - MLP AUC Score: 0.8220\n",
      "Dataset: Dataset_41 - MLP AUC Score: 0.9435\n",
      "Dataset: Dataset_42 - MLP AUC Score: 0.9371\n",
      "Dataset: Dataset_43 - MLP AUC Score: 0.8099\n",
      "Dataset: Dataset_44 - MLP AUC Score: 1.0000\n",
      "Dataset: Dataset_45 - MLP AUC Score: 1.0000\n",
      "Dataset: Dataset_46 - MLP AUC Score: 0.9079\n",
      "Dataset: Dataset_47 - MLP AUC Score: 0.6071\n",
      "Dataset: Dataset_48 - MLP AUC Score: 0.9469\n",
      "Dataset: Dataset_49 - MLP AUC Score: 0.9651\n",
      "Dataset: Dataset_5 - MLP AUC Score: 0.9300\n",
      "Dataset: Dataset_6 - MLP AUC Score: 0.9694\n",
      "Dataset: Dataset_7 - MLP AUC Score: 0.9638\n",
      "Dataset: Dataset_8 - MLP AUC Score: 0.8036\n",
      "Dataset: Dataset_9 - MLP AUC Score: 0.8798\n"
     ]
    }
   ],
   "source": [
    "# MLP (Multi-Layer Perceptron)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from utils import standardize_data, calculate_auc_score, save_predictions_to_csv\n",
    "\n",
    "# Initialize lists to store results\n",
    "mlp_models = []\n",
    "mlp_auc_scores = []\n",
    "\n",
    "# Loop through each dataset and train an MLP model\n",
    "for i, dataset_name in enumerate(dataset_names):\n",
    "    # Split the dataset into training and testing sets\n",
    "    tmp_X_train, tmp_X_test, tmp_y_train, tmp_y_test = train_test_split(X_trains[i], y_trains[i], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Standardize the data (important for MLP)\n",
    "    tmp_X_train, tmp_X_test = standardize_data(tmp_X_train, tmp_X_test)\n",
    "    \n",
    "    # Train MLP model\n",
    "    mlp_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "    mlp_model.fit(tmp_X_train, tmp_y_train.squeeze())\n",
    "    mlp_models.append(mlp_model)\n",
    "    \n",
    "    # Calculate the AUC score for the current dataset\n",
    "    auc_score = calculate_auc_score(mlp_model, tmp_X_test, tmp_y_test)\n",
    "    mlp_auc_scores.append(auc_score)\n",
    "    \n",
    "    # Print the AUC score for the current dataset\n",
    "    print(f\"Dataset: {dataset_name} - MLP AUC Score: {auc_score:.4f}\")\n",
    "    \n",
    "    # Predict probabilities on the test set and save results as binary (0/1)\n",
    "    y_prob = mlp_model.predict_proba(tmp_X_test)[:, 1]\n",
    "    save_predictions_to_csv(y_prob, dataset_name, folder_path='./Competition_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512f84d2-53c6-46c4-8901-a04ef7f19d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
