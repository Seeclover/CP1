{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "from utils import save_predictions_to_csv, standardize_data, calculate_auc_score, compare_auc_scores\n",
    "from natsort import natsorted\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names=[]\n",
    "X_trains=[]\n",
    "y_trains=[]\n",
    "X_tests=[]\n",
    "\n",
    "for folder_name in natsorted(os.listdir(\"./Competition_data\")):\n",
    "    dataset_names.append(folder_name)\n",
    "    X_trains.append(pd.read_csv(f\"./Competition_data/{folder_name}/X_train.csv\",header=0))\n",
    "    y_trains.append(pd.read_csv(f\"./Competition_data/{folder_name}/y_train.csv\",header=0))\n",
    "    X_tests.append(pd.read_csv(f\"./Competition_data/{folder_name}/X_test.csv\",header=0))\n",
    "\n",
    "def preprocess_data(X_train, y_train, X_test):\n",
    "\n",
    "    # 區分數值型和類別型特徵\n",
    "    numeric_features = X_train.select_dtypes(include=['float']).columns\n",
    "    categorical_features = X_train.select_dtypes(include=['int']).columns\n",
    "\n",
    "    # 將類別型特徵轉換為索引\n",
    "    categorical_feature_indices = [X_train.columns.get_loc(col) for col in categorical_features]\n",
    "\n",
    "    # 類別不平衡處理\n",
    "    if len(categorical_feature_indices) == 0:\n",
    "        smote = SMOTE(random_state=40)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        categorical_feature_indices_bool = [i in categorical_feature_indices for i in range(X_train.shape[1])]\n",
    "        smote_nc = SMOTENC(categorical_features=categorical_feature_indices_bool, random_state=41)\n",
    "        X_train, y_train = smote_nc.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # 數值型特徵標準化\n",
    "    numeric_transformer = MinMaxScaler()\n",
    "    X_train_numeric = numeric_transformer.fit_transform(X_train[numeric_features])\n",
    "    X_test_numeric = numeric_transformer.transform(X_test[numeric_features])\n",
    "\n",
    "    # 類別型特徵目標編碼\n",
    "    if len(categorical_features) > 0:\n",
    "        categorical_transformer = TargetEncoder(cols=categorical_features)\n",
    "        X_train_categorical = categorical_transformer.fit_transform(X_train[categorical_features], y_train)\n",
    "        X_test_categorical = categorical_transformer.transform(X_test[categorical_features])\n",
    "    else:\n",
    "        X_train_categorical = np.empty((X_train_numeric.shape[0], 0))\n",
    "        X_test_categorical = np.empty((X_test_numeric.shape[0], 0))\n",
    "\n",
    "    # 合併處理後的特徵\n",
    "    X_train = np.hstack((X_train_numeric, X_train_categorical))\n",
    "    X_test = np.hstack((X_test_numeric, X_test_categorical))\n",
    "\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_auc_scores = []\n",
    "\n",
    "for i in range(len(X_trains)):\n",
    "    X_train, y_train, X_test = preprocess_data(X_trains[i], y_trains[i].values.ravel(), X_tests[i])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_predictions_all_folds = []\n",
    "    fold_auc_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold = X_train[train_idx, :]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx, :]\n",
    "        y_val_fold = y_train[val_idx]\n",
    "\n",
    "        # 提前訓練基模型\n",
    "        rf = BaggingClassifier(estimator=RandomForestClassifier(), n_estimators=10, random_state=43, n_jobs=-1)\n",
    "        rf.fit(X_train_fold, y_train_fold)\n",
    "        rf_val_pred = rf.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        etc = BaggingClassifier(estimator=ExtraTreesClassifier(), n_estimators=10, random_state=44, n_jobs=-1)\n",
    "        etc.fit(X_train_fold, y_train_fold)\n",
    "        etc_val_pred = etc.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=200, max_depth=6, reg_alpha=0.1, reg_lambda=0.1, eval_metric='auc',\n",
    "              n_jobs= -1, early_stopping_rounds=5, random_state=45\n",
    "        )\n",
    "        xgb.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)],verbose = 0)\n",
    "        xgb_val_pred = xgb.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        lgbm = LGBMClassifier(\n",
    "            n_estimators=200, max_depth=6, reg_alpha=0.1, reg_lambda=0.1, min_child_samples = 5,\n",
    "              min_split_gain=0.01, early_stopping_round=5, n_jobs=-1, verbose=-1, random_state=46\n",
    "        )\n",
    "        lgbm.fit(X_train_fold, y_train_fold, eval_metric='auc', eval_set=[(X_val_fold, y_val_fold)])\n",
    "        lgbm_val_pred = lgbm.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        gbc = GradientBoostingClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=47)\n",
    "        gbc.fit(X_train_fold, y_train_fold)\n",
    "        gbc_val_pred = gbc.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        adaboost = AdaBoostClassifier(n_estimators=200, learning_rate=0.1, random_state=48)\n",
    "        adaboost.fit(X_train_fold, y_train_fold)\n",
    "        adaboost_val_pred = adaboost.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        catboost = CatBoostClassifier(iterations=200, learning_rate=0.1, depth=6, verbose=0, random_state=49)\n",
    "        catboost.fit(X_train_fold,y_train_fold)\n",
    "        catboost_val_pred = catboost.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        hist_gb = HistGradientBoostingClassifier(max_iter=200, max_depth=6, learning_rate=0.1, random_state=50)\n",
    "        hist_gb.fit(X_train_fold,y_train_fold)\n",
    "        hist_gb_val_pred = hist_gb.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        '''\n",
    "        easy_ensemble = EasyEnsembleClassifier(n_estimators=10, random_state=51, n_jobs=-1)\n",
    "        easy_ensemble.fit(X_train_fold,y_train_fold)\n",
    "        easy_ensemble_val_pred = easy_ensemble.predict_proba(X_val_fold)[:, 1]\n",
    "        '''\n",
    "\n",
    "        # 不需要提前訓練的模型\n",
    "        lg = LogisticRegression(max_iter=1000, random_state=52, n_jobs=-1)\n",
    "        svm = SVC(kernel='rbf', C=0.5, gamma='auto', probability=True, random_state=53)\n",
    "        nusvc = NuSVC(probability=True, random_state=54)\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(100,50,), alpha=0.0001, learning_rate='adaptive', random_state=57)\n",
    "        bnb = BernoulliNB()\n",
    "        gnb = GaussianNB()\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "        # 堆疊模型\n",
    "        stk = StackingClassifier(\n",
    "            estimators=[('lg',lg),('svm',svm),('nusvc',nusvc),('mlp',mlp),('bnb',bnb),('gnb',gnb),('lda',lda)],\n",
    "            final_estimator=lg,\n",
    "            stack_method='predict_proba',\n",
    "            cv=3,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        stk.fit(X_train_fold, y_train_fold)\n",
    "        stk_val_pred = stk.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        rf_auc = roc_auc_score(y_val_fold, rf_val_pred)\n",
    "        etc_auc = roc_auc_score(y_val_fold, etc_val_pred)\n",
    "        xgb_auc = roc_auc_score(y_val_fold, xgb_val_pred)\n",
    "        lgbm_auc = roc_auc_score(y_val_fold, lgbm_val_pred)\n",
    "        gbc_auc = roc_auc_score(y_val_fold, gbc_val_pred)\n",
    "        adaboost_auc = roc_auc_score(y_val_fold, adaboost_val_pred)\n",
    "        catboost_auc = roc_auc_score(y_val_fold, catboost_val_pred)\n",
    "        hist_gb_auc = roc_auc_score(y_val_fold, hist_gb_val_pred)\n",
    "        #easy_ensemble_auc = roc_auc_score(y_val_fold, easy_ensemble_val_pred)\n",
    "        stk_auc = roc_auc_score(y_val_fold, stk_val_pred)\n",
    "\n",
    "        model_aucs = [rf_auc, etc_auc, xgb_auc, lgbm_auc, gbc_auc, adaboost_auc, catboost_auc, hist_gb_auc, stk_auc]\n",
    "        \n",
    "        normalized_weights = [auc / sum(model_aucs) for auc in model_aucs]\n",
    "\n",
    "        # 組合基模型預測概率\n",
    "        meta_features = np.column_stack([rf_val_pred, etc_val_pred, xgb_val_pred, lgbm_val_pred, gbc_val_pred, adaboost_val_pred,\n",
    "                                          catboost_val_pred, hist_gb_val_pred, stk_val_pred])\n",
    "        weighted_meta_features = np.average(meta_features, axis=1, weights=normalized_weights)\n",
    "        meta_model = lg\n",
    "        meta_model.fit(weighted_meta_features.reshape(-1,1), y_val_fold)\n",
    "\n",
    "        # 驗證集預測\n",
    "        y_val_pred = meta_model.predict_proba(weighted_meta_features.reshape(-1,1))[:, 1]\n",
    "        val_auc = roc_auc_score(y_val_fold, y_val_pred)\n",
    "        print(f\"Validation AUC for fold {fold + 1}: {val_auc:.4f}\")\n",
    "        fold_auc_scores.append(val_auc)\n",
    "\n",
    "        # 測試集預測\n",
    "        rf_test_pred = rf.predict_proba(X_test)[:, 1]\n",
    "        etc_test_pred = etc.predict_proba(X_test)[:, 1]\n",
    "        xgb_test_pred = xgb.predict_proba(X_test)[:, 1]\n",
    "        lgbm_test_pred = lgbm.predict_proba(X_test)[:, 1]\n",
    "        gbc_test_pred = gbc.predict_proba(X_test)[:, 1]\n",
    "        adaboost_test_pred = adaboost.predict_proba(X_test)[:, 1]\n",
    "        catboost_test_pred = catboost.predict_proba(X_test)[:, 1]\n",
    "        hist_gb_test_pred = hist_gb.predict_proba(X_test)[:, 1]\n",
    "        #easy_ensemble_test_pred = easy_ensemble.predict_proba(X_test)[:, 1]\n",
    "        stk_test_pred = stk.predict_proba(X_test)[:, 1]\n",
    "        test_meta_features = np.column_stack([rf_test_pred, etc_test_pred, xgb_test_pred, lgbm_test_pred, gbc_test_pred, adaboost_test_pred,\n",
    "                                               catboost_test_pred, hist_gb_test_pred, stk_test_pred])\n",
    "        weighted_test_feature = np.average(test_meta_features, axis=1, weights=normalized_weights)\n",
    "        y_test_pred = meta_model.predict_proba(test_meta_features.reshape(-1,1))[:, 1]\n",
    "        test_predictions_all_folds.append(y_test_pred)\n",
    "\n",
    "    # 計算加權測試集預測\n",
    "    total_auc = sum(fold_auc_scores)\n",
    "    fold_weights = [auc / total_auc for auc in fold_auc_scores]\n",
    "    test_predictions_final = np.average(test_predictions_all_folds, axis=0, weights=fold_weights)\n",
    "\n",
    "    # 計算平均驗證 AUC\n",
    "    avg_val_auc = np.mean(fold_auc_scores)\n",
    "    print(f\"Average AUC for {i+1}'th Dataset: {avg_val_auc:.4f}\")\n",
    "    validation_auc_scores.append(avg_val_auc)\n",
    "\n",
    "    # 儲存測試結果 CSV\n",
    "    df = pd.DataFrame(test_predictions_final, columns=['y_predict_proba'])\n",
    "    df.to_csv(f'./Competition_data/{dataset_names[i]}/y_predict.csv', index=False, header=True)\n",
    "\n",
    "# 儲存 AUC 分數為 CSV 文件/\n",
    "auc_list = pd.DataFrame(validation_auc_scores, columns=[\"Validation AUC\"])\n",
    "auc_list.to_csv('./validation_auc_scores_test.csv', index_label='Dataset_Index', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_auc_scores = []\n",
    "\n",
    "for i in range(2,3):\n",
    "\n",
    "    X_train, y_train, X_test = preprocess_data(X_trains[i], y_trains[i].values.ravel(), X_tests[i])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_predictions_all_folds = []\n",
    "    fold_auc_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "\n",
    "        X_train_fold = X_train[train_idx, :]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx, :]\n",
    "        y_val_fold = y_train[val_idx]\n",
    "\n",
    "        # 提前訓練基模型\n",
    "        #rf = BaggingClassifier(estimator=RandomForestClassifier(min_samples_leaf=3, min_samples_split=3), n_estimators=10, random_state=43, n_jobs=-1)\n",
    "        rf = RandomForestClassifier(n_estimators=500, max_depth=20, min_samples_split=3, min_samples_leaf=3, n_jobs=-1, random_state=43)\n",
    "        rf.fit(X_train_fold, y_train_fold)\n",
    "        rf_val_pred = rf.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        #etc = BaggingClassifier(estimator=ExtraTreesClassifier(min_samples_leaf=3, min_samples_split=3), n_estimators=10, random_state=44, n_jobs=-1)\n",
    "        etc = ExtraTreesClassifier(n_estimators=500, max_depth=20, min_samples_split=3, min_samples_leaf=4 ,random_state=44, n_jobs=-1)\n",
    "        etc.fit(X_train_fold, y_train_fold)\n",
    "        etc_val_pred = etc.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        xgb = XGBClassifier(\n",
    "            n_estimators=200, max_depth=6, reg_alpha=0.1, reg_lambda=0.1, eval_metric='auc',\n",
    "              n_jobs= -1, early_stopping_rounds=5, random_state=45\n",
    "        )\n",
    "        xgb.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)],verbose = 0)\n",
    "        xgb_val_pred = xgb.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        lgbm = LGBMClassifier(\n",
    "            n_estimators=200, max_depth=6, reg_alpha=0.1, reg_lambda=0.1, min_child_samples = 5,\n",
    "              min_split_gain=0.01, early_stopping_round=10, n_jobs=-1, verbose=-1, random_state=46\n",
    "        )\n",
    "        lgbm.fit(X_train_fold, y_train_fold, eval_metric='auc', eval_set=[(X_val_fold, y_val_fold)])\n",
    "        lgbm_val_pred = lgbm.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        gbc = GradientBoostingClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=47)\n",
    "        gbc.fit(X_train_fold, y_train_fold)\n",
    "        gbc_val_pred = gbc.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        adaboost = AdaBoostClassifier(n_estimators=200, learning_rate=0.1, random_state=48)\n",
    "        adaboost.fit(X_train_fold, y_train_fold)\n",
    "        adaboost_val_pred = adaboost.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        catboost = CatBoostClassifier(iterations=200, learning_rate=0.1, depth=6, verbose=0, random_state=49)\n",
    "        catboost.fit(X_train_fold,y_train_fold)\n",
    "        catboost_val_pred = catboost.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        hist_gb = HistGradientBoostingClassifier(max_iter=200, max_depth=6, learning_rate=0.1, early_stopping=True,  random_state=50)\n",
    "        hist_gb.fit(X_train_fold,y_train_fold)\n",
    "        hist_gb_val_pred = hist_gb.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        # 不需要提前訓練的模型\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=(100, 50), learning_rate='adaptive', max_iter=1000, alpha=0.001, early_stopping=True, random_state=49)\n",
    "        svm = SVC(kernel='rbf', C=0.5, gamma='auto', probability=True, random_state=50)\n",
    "        lg = LogisticRegression(max_iter=500, random_state=51)\n",
    "        bnb = BernoulliNB()\n",
    "        gnb = GaussianNB()\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        nusvc = NuSVC(probability=True, random_state=52)\n",
    "\n",
    "        # 堆疊模型\n",
    "        stacking_model = StackingClassifier(\n",
    "            estimators=[('mlp', mlp),('svm', svm),('lg',lg),('bnb',bnb),('gnb',gnb),('lda',lda),('nusvc',nusvc)],\n",
    "            final_estimator=lg,\n",
    "            stack_method='predict_proba',\n",
    "            cv=3,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        stacking_model.fit(X_train_fold, y_train_fold)\n",
    "        stk_val_pred = stacking_model.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        # 組合基模型預測概率\n",
    "        meta_features = np.column_stack([rf_val_pred, etc_val_pred, xgb_val_pred, lgbm_val_pred, gbc_val_pred,\n",
    "                                          adaboost_val_pred,  catboost_val_pred, hist_gb_val_pred, stk_val_pred])\n",
    "        meta_model = lg\n",
    "        meta_model.fit(meta_features, y_val_fold)\n",
    "\n",
    "        # 驗證集預測\n",
    "        y_val_pred = meta_model.predict_proba(meta_features)[:, 1]\n",
    "        val_auc = roc_auc_score(y_val_fold, y_val_pred)\n",
    "        print(f\"Validation AUC for fold {fold + 1}: {val_auc:.4f}\")\n",
    "        fold_auc_scores.append(val_auc)\n",
    "\n",
    "        # 測試集預測\n",
    "        rf_test_pred = rf.predict_proba(X_test)[:, 1]\n",
    "        etc_test_pred = etc.predict_proba(X_test)[:, 1]\n",
    "        xgb_test_pred = xgb.predict_proba(X_test)[:, 1]\n",
    "        lgbm_test_pred = lgbm.predict_proba(X_test)[:, 1]\n",
    "        gbc_test_pred = gbc.predict_proba(X_test)[:, 1]\n",
    "        adaboost_test_pred = adaboost.predict_proba(X_test)[:, 1]\n",
    "        stk_test_pred = stacking_model.predict_proba(X_test)[:, 1]\n",
    "        catboost_test_pred = catboost.predict_proba(X_test)[:, 1]\n",
    "        hist_gb_test_pred = hist_gb.predict_proba(X_test)[:, 1]\n",
    "        test_meta_features = np.column_stack([rf_test_pred, etc_test_pred, xgb_test_pred, lgbm_test_pred,\n",
    "                                              gbc_test_pred, adaboost_test_pred, catboost_test_pred, hist_gb_test_pred, stk_test_pred])\n",
    "        y_test_pred = meta_model.predict_proba(test_meta_features)[:, 1]\n",
    "        test_predictions_all_folds.append(y_test_pred)\n",
    "\n",
    "    # 計算加權測試集預測\n",
    "    total_auc = sum(fold_auc_scores)\n",
    "    fold_weights = [auc / total_auc for auc in fold_auc_scores]\n",
    "    test_predictions_final = np.average(test_predictions_all_folds, axis=0, weights=fold_weights)\n",
    "\n",
    "    # 計算平均驗證 AUC\n",
    "    avg_val_auc = np.mean(fold_auc_scores)\n",
    "    print(f\"Average AUC for {i+1}'th Dataset: {avg_val_auc:.4f}\")\n",
    "    validation_auc_scores.append(avg_val_auc)\n",
    "\n",
    "    # 儲存測試結果 CSV\n",
    "    df = pd.DataFrame(test_predictions_final, columns=['y_predict_proba'])\n",
    "    df.to_csv(f'./Competition_data/{dataset_names[i]}/y_predict.csv', index=False, header=True)\n",
    "\n",
    "# 儲存 AUC 分數為 CSV 文件\n",
    "auc_list = pd.DataFrame(validation_auc_scores, columns=[\"Validation AUC\"])\n",
    "auc_list.to_csv('./validation_auc_scores.csv', index_label='Dataset_Index', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC for fold 1: 0.9514\n",
      "Validation AUC for fold 2: 0.9319\n",
      "Validation AUC for fold 3: 0.9217\n",
      "Validation AUC for fold 4: 0.9324\n",
      "Validation AUC for fold 5: 0.9524\n",
      "Average AUC for 1'th Dataset: 0.9379\n",
      "Validation AUC for fold 1: 0.9997\n",
      "Validation AUC for fold 2: 0.9982\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 1.0000\n",
      "Validation AUC for fold 5: 1.0000\n",
      "Average AUC for 2'th Dataset: 0.9996\n",
      "Validation AUC for fold 1: 0.9184\n",
      "Validation AUC for fold 2: 1.0000\n",
      "Validation AUC for fold 3: 0.9592\n",
      "Validation AUC for fold 4: 0.9592\n",
      "Validation AUC for fold 5: 1.0000\n",
      "Average AUC for 3'th Dataset: 0.9673\n",
      "Validation AUC for fold 1: 0.9943\n",
      "Validation AUC for fold 2: 0.9974\n",
      "Validation AUC for fold 3: 0.9963\n",
      "Validation AUC for fold 4: 0.9970\n",
      "Validation AUC for fold 5: 0.9984\n",
      "Average AUC for 4'th Dataset: 0.9967\n",
      "Validation AUC for fold 1: 0.9992\n",
      "Validation AUC for fold 2: 0.9995\n",
      "Validation AUC for fold 3: 0.9989\n",
      "Validation AUC for fold 4: 1.0000\n",
      "Validation AUC for fold 5: 0.9984\n",
      "Average AUC for 5'th Dataset: 0.9992\n",
      "Validation AUC for fold 1: 0.9945\n",
      "Validation AUC for fold 2: 0.9986\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 0.9957\n",
      "Validation AUC for fold 5: 0.9950\n",
      "Average AUC for 6'th Dataset: 0.9968\n",
      "Validation AUC for fold 1: 1.0000\n",
      "Validation AUC for fold 2: 0.9998\n",
      "Validation AUC for fold 3: 0.9985\n",
      "Validation AUC for fold 4: 0.9993\n",
      "Validation AUC for fold 5: 0.9971\n",
      "Average AUC for 7'th Dataset: 0.9989\n",
      "Validation AUC for fold 1: 0.9600\n",
      "Validation AUC for fold 2: 0.9350\n",
      "Validation AUC for fold 3: 0.9549\n",
      "Validation AUC for fold 4: 0.9514\n",
      "Validation AUC for fold 5: 0.9601\n",
      "Average AUC for 8'th Dataset: 0.9523\n",
      "Validation AUC for fold 1: 0.9600\n",
      "Validation AUC for fold 2: 0.9156\n",
      "Validation AUC for fold 3: 0.9156\n",
      "Validation AUC for fold 4: 0.9190\n",
      "Validation AUC for fold 5: 0.8810\n",
      "Average AUC for 9'th Dataset: 0.9182\n",
      "Validation AUC for fold 1: 0.8932\n",
      "Validation AUC for fold 2: 0.8411\n",
      "Validation AUC for fold 3: 0.8040\n",
      "Validation AUC for fold 4: 0.8771\n",
      "Validation AUC for fold 5: 0.8976\n",
      "Average AUC for 10'th Dataset: 0.8626\n",
      "Validation AUC for fold 1: 1.0000\n",
      "Validation AUC for fold 2: 0.9556\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 0.9889\n",
      "Validation AUC for fold 5: 0.8889\n",
      "Average AUC for 11'th Dataset: 0.9667\n",
      "Validation AUC for fold 1: 1.0000\n",
      "Validation AUC for fold 2: 1.0000\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 0.9897\n",
      "Validation AUC for fold 5: 1.0000\n",
      "Average AUC for 12'th Dataset: 0.9979\n"
     ]
    }
   ],
   "source": [
    "validation_auc_scores = []\n",
    "\n",
    "for i in range(len(X_trains)):\n",
    "    X_train, y_train, X_test = preprocess_data(X_trains[i], y_trains[i].values.ravel(), X_tests[i])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_predictions_all_folds = []\n",
    "    fold_auc_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold = X_train[train_idx, :]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx, :]\n",
    "        y_val_fold = y_train[val_idx]\n",
    "\n",
    "        # 提前訓練基模型\n",
    "        rf = BaggingClassifier(estimator=RandomForestClassifier(), n_estimators=10, random_state=43, n_jobs=-1)\n",
    "        rf.fit(X_train_fold, y_train_fold)\n",
    "        rf_val_pred = rf.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        etc = BaggingClassifier(estimator=ExtraTreesClassifier(), n_estimators=10, random_state=44, n_jobs=-1) \n",
    "        etc.fit(X_train_fold, y_train_fold)\n",
    "        etc_val_pred = etc.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        svm = BaggingClassifier(estimator=SVC(), n_estimators=10, random_state=45, n_jobs=-1)\n",
    "        svm.fit(X_train_fold,y_train_fold)\n",
    "        svm_val_pred = svm.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        nusvc = BaggingClassifier(estimator=NuSVC(), n_estimators=10, random_state=46, n_jobs=-1)\n",
    "        nusvc.fit(X_train_fold, y_train_fold)\n",
    "        nusvc_val_pred = nusvc.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        mlp = BaggingClassifier(estimator=MLPClassifier(), n_estimators=10, random_state=47, n_jobs=-1)\n",
    "        mlp.fit(X_train_fold,y_train_fold)\n",
    "        mlp_val_pred = mlp.predict_proba(X_val_fold)[:,1]\n",
    "\n",
    "        xgb = XGBClassifier(n_estimators=200, max_depth=6, reg_alpha=0.1, reg_lambda=0.1,\n",
    "                             eval_metric='auc', early_stopping_rounds=5, random_state=48, n_jobs=-1)\n",
    "        xgb.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)],verbose = 0)\n",
    "        xgb_val_pred = xgb.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        lgbm = LGBMClassifier(n_estimators=200, max_depth=6, reg_alpha=0.1, reg_lambda=0.1, min_child_samples=5,\n",
    "                               min_split_gain=0.01, early_stopping_round=5, verbose=-1, random_state=49, n_jobs=-1)\n",
    "        lgbm.fit(X_train_fold, y_train_fold, eval_metric='auc', eval_set=[(X_val_fold, y_val_fold)])\n",
    "        lgbm_val_pred = lgbm.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        gbc = GradientBoostingClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=50)\n",
    "        gbc.fit(X_train_fold, y_train_fold)\n",
    "        gbc_val_pred = gbc.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        adaboost = AdaBoostClassifier(n_estimators=200, learning_rate=0.1, random_state=51)\n",
    "        adaboost.fit(X_train_fold, y_train_fold)\n",
    "        adaboost_val_pred = adaboost.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        # 不需要提前訓練的模型\n",
    "        lg = LogisticRegression(max_iter=1000, random_state=52)\n",
    "        bnb = BernoulliNB()\n",
    "        gnb = GaussianNB()\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "        # 堆疊模型\n",
    "        stacking_model = StackingClassifier(\n",
    "            estimators=[('lg',lg),('bnb',bnb),('gnb',gnb),('lda',lda)],\n",
    "            final_estimator=BaggingClassifier(estimator=MLPClassifier(), n_estimators=10, random_state=53, n_jobs=-1),\n",
    "            stack_method='predict_proba',\n",
    "            cv=3,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        stacking_model.fit(X_train_fold, y_train_fold)\n",
    "        stk_val_pred = stacking_model.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        # 組合基模型預測概率\n",
    "        meta_features = np.column_stack([rf_val_pred, etc_val_pred, svm_val_pred, nusvc_val_pred, mlp_val_pred,\n",
    "                                          xgb_val_pred, lgbm_val_pred, gbc_val_pred, adaboost_val_pred, stk_val_pred])\n",
    "        meta_model = BaggingClassifier(estimator=MLPClassifier(), n_estimators=10, random_state=54, n_jobs=-1)\n",
    "        meta_model.fit(meta_features, y_val_fold)\n",
    "\n",
    "        # 驗證集預測\n",
    "        y_val_pred = meta_model.predict_proba(meta_features)[:, 1]\n",
    "        val_auc = roc_auc_score(y_val_fold, y_val_pred)\n",
    "        print(f\"Validation AUC for fold {fold + 1}: {val_auc:.4f}\")\n",
    "        fold_auc_scores.append(val_auc)\n",
    "\n",
    "        # 測試集預測\n",
    "        rf_test_pred = rf.predict_proba(X_test)[:, 1]\n",
    "        etc_test_pred = etc.predict_proba(X_test)[:, 1]\n",
    "        svm_test_pred = svm.predict_proba(X_test)[:, 1]\n",
    "        nusvc_test_pred = nusvc.predict_proba(X_test)[:, 1]\n",
    "        mlp_test_pred = mlp.predict_proba(X_test)[:, 1]\n",
    "        xgb_test_pred = xgb.predict_proba(X_test)[:, 1]\n",
    "        lgbm_test_pred = lgbm.predict_proba(X_test)[:, 1]\n",
    "        gbc_test_pred = gbc.predict_proba(X_test)[:, 1]\n",
    "        adaboost_test_pred = adaboost.predict_proba(X_test)[:, 1]\n",
    "        stk_test_pred = stacking_model.predict_proba(X_test)[:, 1]\n",
    "        test_meta_features = np.column_stack([rf_test_pred, etc_test_pred, svm_test_pred, nusvc_test_pred, mlp_test_pred,\n",
    "                                              xgb_test_pred, lgbm_test_pred, gbc_test_pred, adaboost_test_pred, stk_test_pred])\n",
    "        y_test_pred = meta_model.predict_proba(test_meta_features)[:, 1]\n",
    "        test_predictions_all_folds.append(y_test_pred)\n",
    "\n",
    "    # 計算加權測試集預測\n",
    "    total_auc = sum(fold_auc_scores)\n",
    "    fold_weights = [auc / total_auc for auc in fold_auc_scores]\n",
    "    test_predictions_final = np.average(test_predictions_all_folds, axis=0, weights=fold_weights)\n",
    "\n",
    "    # 計算平均驗證 AUC\n",
    "    avg_val_auc = np.mean(fold_auc_scores)\n",
    "    print(f\"Average AUC for {i+1}'th Dataset: {avg_val_auc:.4f}\")\n",
    "    validation_auc_scores.append(avg_val_auc)\n",
    "\n",
    "    # 儲存測試結果 CSV\n",
    "    df = pd.DataFrame(test_predictions_final, columns=['y_predict_proba'])\n",
    "    df.to_csv(f'./Competition_data/{dataset_names[i]}/y_predict.csv', index=False, header=True)\n",
    "\n",
    "# 儲存 AUC 分數為 CSV 文件\n",
    "auc_list = pd.DataFrame(validation_auc_scores, columns=[\"Validation AUC\"])\n",
    "auc_list.to_csv('./validation_auc_scores.csv', index_label='Dataset_Index', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
