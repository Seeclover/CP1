{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "from utils import save_predictions_to_csv, standardize_data, calculate_auc_score, compare_auc_scores\n",
    "from natsort import natsorted\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "- 選出數值以及類別型特徵\n",
    "- 對資料做 SMOTENC ，如果dataset只有數值型特徵就做 SMOTE\n",
    "- 數值特徵做 MinMaxScalar()\n",
    "- 類別特徵做 TargetEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names=[]\n",
    "X_trains=[]\n",
    "y_trains=[]\n",
    "X_tests=[]\n",
    "\n",
    "for folder_name in natsorted(os.listdir(\"./Competition_data\")):\n",
    "    dataset_names.append(folder_name)\n",
    "    X_trains.append(pd.read_csv(f\"./Competition_data/{folder_name}/X_train.csv\",header=0))\n",
    "    y_trains.append(pd.read_csv(f\"./Competition_data/{folder_name}/y_train.csv\",header=0))\n",
    "    X_tests.append(pd.read_csv(f\"./Competition_data/{folder_name}/X_test.csv\",header=0))\n",
    "\n",
    "def preprocess_data(X_train, y_train, X_test):\n",
    "\n",
    "    # 區分數值型和類別型特徵\n",
    "    numeric_features = X_train.select_dtypes(include=['float']).columns\n",
    "    categorical_features = X_train.select_dtypes(include=['int']).columns\n",
    "\n",
    "    # 將類別型特徵轉換為索引\n",
    "    categorical_feature_indices = [X_train.columns.get_loc(col) for col in categorical_features]\n",
    "\n",
    "    # 類別不平衡處理\n",
    "    if len(categorical_feature_indices) == 0:\n",
    "        smote = SMOTE(random_state=40)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        categorical_feature_indices_bool = [i in categorical_feature_indices for i in range(X_train.shape[1])]\n",
    "        smote_nc = SMOTENC(categorical_features=categorical_feature_indices_bool, random_state=41)\n",
    "        X_train, y_train = smote_nc.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # 數值型特徵標準化\n",
    "    numeric_transformer = MinMaxScaler()\n",
    "    X_train_numeric = numeric_transformer.fit_transform(X_train[numeric_features])\n",
    "    X_test_numeric = numeric_transformer.transform(X_test[numeric_features])\n",
    "\n",
    "    # 類別型特徵目標編碼\n",
    "    if len(categorical_features) > 0:\n",
    "        categorical_transformer = TargetEncoder(cols=categorical_features)\n",
    "        X_train_categorical = categorical_transformer.fit_transform(X_train[categorical_features], y_train)\n",
    "        X_test_categorical = categorical_transformer.transform(X_test[categorical_features])\n",
    "    else:\n",
    "        X_train_categorical = np.empty((X_train_numeric.shape[0], 0))\n",
    "        X_test_categorical = np.empty((X_test_numeric.shape[0], 0))\n",
    "\n",
    "    # 合併處理後的特徵\n",
    "    X_train = np.hstack((X_train_numeric, X_train_categorical))\n",
    "    X_test = np.hstack((X_test_numeric, X_test_categorical))\n",
    "\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "- 5-fold validation\n",
    "- 用 Bagging Boosting Staking 做 ensemble\n",
    "- Bagging -> randomforest, extratree, svm, nusvc, mlp\n",
    "- Boosting -> xgb, lightgbm, gbc, adaboost, catboost, hist_gb\n",
    "- Other -> easy_ensemble\n",
    "- Staking -> lineargression, BernoulliNB, GaussianNB, LinearDiscriminantAnalysis ; final_estimator = lg\n",
    "- final model -> mlp 用每個模型的 val 加權去預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC for fold 1: 0.8163\n",
      "Validation AUC for fold 2: 0.9796\n",
      "Validation AUC for fold 3: 0.9184\n",
      "Validation AUC for fold 4: 1.0000\n",
      "Validation AUC for fold 5: 1.0000\n",
      "Average AUC for 3'th Dataset: 0.9429\n"
     ]
    }
   ],
   "source": [
    "validation_auc_scores = []\n",
    "\n",
    "for i in range(2,3):\n",
    "    X_train, y_train, X_test = preprocess_data(X_trains[i], y_trains[i].values.ravel(), X_tests[i])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_predictions_all_folds = []\n",
    "    fold_auc_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold = X_train[train_idx, :]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx, :]\n",
    "        y_val_fold = y_train[val_idx]\n",
    "\n",
    "        # 提前訓練基模型\n",
    "        rf = BaggingClassifier(estimator=RandomForestClassifier(), n_estimators=10, random_state=43, n_jobs=-1)\n",
    "        rf.fit(X_train_fold, y_train_fold)\n",
    "        rf_val_pred = rf.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        etc = BaggingClassifier(estimator=ExtraTreesClassifier(), n_estimators=10, random_state=44, n_jobs=-1) \n",
    "        etc.fit(X_train_fold, y_train_fold)\n",
    "        etc_val_pred = etc.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        svm = BaggingClassifier(estimator=SVC(), n_estimators=10, random_state=45, n_jobs=-1)\n",
    "        svm.fit(X_train_fold,y_train_fold)\n",
    "        svm_val_pred = svm.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        nusvc = BaggingClassifier(estimator=NuSVC(), n_estimators=10, random_state=46, n_jobs=-1)\n",
    "        nusvc.fit(X_train_fold, y_train_fold)\n",
    "        nusvc_val_pred = nusvc.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        mlp = BaggingClassifier(estimator=MLPClassifier(), n_estimators=10, random_state=47, n_jobs=-1)\n",
    "        mlp.fit(X_train_fold,y_train_fold)\n",
    "        mlp_val_pred = mlp.predict_proba(X_val_fold)[:,1]\n",
    "\n",
    "        xgb = XGBClassifier(n_estimators=200, max_depth=6, reg_alpha=0.1, reg_lambda=0.1,\n",
    "                             eval_metric='auc', early_stopping_rounds=5, random_state=48, n_jobs=-1)\n",
    "        xgb.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)],verbose = 0)\n",
    "        xgb_val_pred = xgb.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        lgbm = LGBMClassifier(n_estimators=200, max_depth=6, reg_alpha=0.1, reg_lambda=0.1, min_child_samples=5,\n",
    "                               min_split_gain=0.01, early_stopping_round=5, verbose=-1, random_state=49, n_jobs=-1)\n",
    "        lgbm.fit(X_train_fold, y_train_fold, eval_metric='auc', eval_set=[(X_val_fold, y_val_fold)])\n",
    "        lgbm_val_pred = lgbm.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        gbc = GradientBoostingClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=50)\n",
    "        gbc.fit(X_train_fold, y_train_fold)\n",
    "        gbc_val_pred = gbc.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        adaboost = AdaBoostClassifier(n_estimators=200, learning_rate=0.1, random_state=51)\n",
    "        adaboost.fit(X_train_fold, y_train_fold)\n",
    "        adaboost_val_pred = adaboost.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        catboost = CatBoostClassifier(iterations=200, learning_rate=0.1, depth=6, verbose=0, early_stopping_rounds=5, random_state=49)\n",
    "        catboost.fit(X_train_fold,y_train_fold)\n",
    "        catboost_val_pred = catboost.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        hist_gb = HistGradientBoostingClassifier(max_iter=200, max_depth=6, learning_rate=0.1, early_stopping=True, random_state=50)\n",
    "        hist_gb.fit(X_train_fold,y_train_fold)\n",
    "        hist_gb_val_pred = hist_gb.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        easy_ensemble = EasyEnsembleClassifier(n_estimators=10, n_jobs=-1, random_state=51)\n",
    "        easy_ensemble.fit(X_train_fold,y_train_fold)\n",
    "        easy_ensemble_val_pred = easy_ensemble.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        # 不需要提前訓練的模型\n",
    "        lg = LogisticRegression(max_iter=1000, random_state=52)\n",
    "        bnb = BernoulliNB()\n",
    "        gnb = GaussianNB()\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "        # 堆疊模型\n",
    "        stacking_model = StackingClassifier(\n",
    "            estimators=[('lg',lg),('bnb',bnb),('gnb',gnb),('lda',lda)],\n",
    "            final_estimator=BaggingClassifier(estimator=XGBClassifier(), n_estimators=10, random_state=53, n_jobs=-1),\n",
    "            stack_method='predict_proba',\n",
    "            cv=3,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        stacking_model.fit(X_train_fold, y_train_fold)\n",
    "        stk_val_pred = stacking_model.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        # 組合基模型預測概率\n",
    "        meta_features = np.column_stack([rf_val_pred, etc_val_pred, svm_val_pred, nusvc_val_pred, mlp_val_pred,\n",
    "                                          xgb_val_pred, lgbm_val_pred, gbc_val_pred, adaboost_val_pred, catboost_val_pred, hist_gb_val_pred, \n",
    "                                          easy_ensemble_val_pred, stk_val_pred])\n",
    "        meta_model = BaggingClassifier(estimator=MLPClassifier(), n_estimators=10, random_state=54, n_jobs=-1)\n",
    "        meta_model.fit(meta_features, y_val_fold)\n",
    "\n",
    "        # 驗證集預測\n",
    "        y_val_pred = meta_model.predict_proba(meta_features)[:, 1]\n",
    "        val_auc = roc_auc_score(y_val_fold, y_val_pred)\n",
    "        print(f\"Validation AUC for fold {fold + 1}: {val_auc:.4f}\")\n",
    "        fold_auc_scores.append(val_auc)\n",
    "\n",
    "        # 測試集預測\n",
    "        rf_test_pred = rf.predict_proba(X_test)[:, 1]\n",
    "        etc_test_pred = etc.predict_proba(X_test)[:, 1]\n",
    "        svm_test_pred = svm.predict_proba(X_test)[:, 1]\n",
    "        nusvc_test_pred = nusvc.predict_proba(X_test)[:, 1]\n",
    "        mlp_test_pred = mlp.predict_proba(X_test)[:, 1]\n",
    "        xgb_test_pred = xgb.predict_proba(X_test)[:, 1]\n",
    "        lgbm_test_pred = lgbm.predict_proba(X_test)[:, 1]\n",
    "        gbc_test_pred = gbc.predict_proba(X_test)[:, 1]\n",
    "        adaboost_test_pred = adaboost.predict_proba(X_test)[:, 1]\n",
    "        catboost_test_pred = catboost.predict_proba(X_test)[:, 1]\n",
    "        hist_gb_test_pred = hist_gb.predict_proba(X_test)[:, 1]\n",
    "        easy_ensemble_test_pred = easy_ensemble.predict_proba(X_test)[:, 1]\n",
    "        stk_test_pred = stacking_model.predict_proba(X_test)[:, 1]\n",
    "        test_meta_features = np.column_stack([rf_test_pred, etc_test_pred, svm_test_pred, nusvc_test_pred, mlp_test_pred, xgb_test_pred,\n",
    "                                               lgbm_test_pred, gbc_test_pred, adaboost_test_pred, catboost_test_pred, hist_gb_test_pred,\n",
    "                                               easy_ensemble_test_pred, stk_test_pred])\n",
    "        \n",
    "        y_test_pred = meta_model.predict_proba(test_meta_features)[:, 1]\n",
    "        test_predictions_all_folds.append(y_test_pred)\n",
    "\n",
    "    # 計算加權測試集預測\n",
    "    total_auc = sum(fold_auc_scores)\n",
    "    fold_weights = [auc / total_auc for auc in fold_auc_scores]\n",
    "    test_predictions_final = np.average(test_predictions_all_folds, axis=0, weights=fold_weights)\n",
    "\n",
    "    # 計算平均驗證 AUC\n",
    "    avg_val_auc = np.mean(fold_auc_scores)\n",
    "    print(f\"Average AUC for {i+1}'th Dataset: {avg_val_auc:.4f}\")\n",
    "    validation_auc_scores.append(avg_val_auc)\n",
    "\n",
    "    # 儲存測試結果 CSV\n",
    "    df = pd.DataFrame(test_predictions_final, columns=['y_predict_proba'])\n",
    "    df.to_csv(f'./Competition_data/{dataset_names[i]}/y_predict.csv', index=False, header=True)\n",
    "\n",
    "# 儲存 AUC 分數為 CSV 文件\n",
    "auc_list = pd.DataFrame(validation_auc_scores, columns=[\"Validation AUC\"])\n",
    "auc_list.to_csv('./validation_auc_scores.csv', index_label='Dataset_Index', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_auc_scores = []\n",
    "\n",
    "# 設置基模型名稱\n",
    "base_models = {\n",
    "    \"rf\": BaggingClassifier(estimator=RandomForestClassifier(), n_estimators=10, random_state=43, n_jobs=-1),\n",
    "    \"etc\": BaggingClassifier(estimator=ExtraTreesClassifier(), n_estimators=10, random_state=44, n_jobs=-1),\n",
    "    \"xgb\": XGBClassifier(n_estimators=200, max_depth=6, reg_alpha=0.1, reg_lambda=0.1, eval_metric='auc', \n",
    "                         early_stopping_rounds=5, random_state=48, n_jobs=-1),\n",
    "    \"lgbm\": LGBMClassifier(n_estimators=200, max_depth=6, reg_alpha=0.1, reg_lambda=0.1, min_child_samples=5, \n",
    "                           min_split_gain=0.01, early_stopping_round=5, verbose=-1, random_state=49, n_jobs=-1),\n",
    "    \"gbc\": GradientBoostingClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=50),\n",
    "}\n",
    "\n",
    "for i in range(2, 3):\n",
    "    X_train, y_train, X_test = preprocess_data(X_trains[i], y_trains[i].values.ravel(), X_tests[i])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_predictions_all_folds = []\n",
    "    fold_auc_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold = X_train[train_idx, :]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx, :]\n",
    "        y_val_fold = y_train[val_idx]\n",
    "\n",
    "        # 訓練基模型並記錄驗證集預測\n",
    "        model_predictions = {}\n",
    "        model_aucs = {}\n",
    "\n",
    "        for model_name, model in base_models.items():\n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            val_pred = model.predict_proba(X_val_fold)[:, 1]\n",
    "            model_predictions[model_name] = val_pred\n",
    "            model_aucs[model_name] = roc_auc_score(y_val_fold, val_pred)\n",
    "\n",
    "        # 篩選 AUC 最好的模型（例如保留前 5 名）\n",
    "        top_models = sorted(model_aucs.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        selected_model_names = [model[0] for model in top_models]\n",
    "        print(f\"Fold {fold + 1}: Selected models - {selected_model_names}\")\n",
    "\n",
    "        # 合併篩選後的基模型預測作為 meta features\n",
    "        meta_features = np.column_stack([model_predictions[name] for name in selected_model_names])\n",
    "        meta_model = BaggingClassifier(estimator=LogisticRegression(), n_estimators=10, random_state=54, n_jobs=-1)\n",
    "        meta_model.fit(meta_features, y_val_fold)\n",
    "\n",
    "        # 驗證集預測\n",
    "        y_val_pred = meta_model.predict_proba(meta_features)[:, 1]\n",
    "        val_auc = roc_auc_score(y_val_fold, y_val_pred)\n",
    "        print(f\"Validation AUC for fold {fold + 1}: {val_auc:.4f}\")\n",
    "        fold_auc_scores.append(val_auc)\n",
    "\n",
    "        # 測試集預測\n",
    "        test_model_predictions = np.column_stack([\n",
    "            base_models[name].predict_proba(X_test)[:, 1] for name in selected_model_names\n",
    "        ])\n",
    "        y_test_pred = meta_model.predict_proba(test_model_predictions)[:, 1]\n",
    "        test_predictions_all_folds.append(y_test_pred)\n",
    "\n",
    "    # 加權測試集預測\n",
    "    total_auc = sum(fold_auc_scores)\n",
    "    fold_weights = [auc / total_auc for auc in fold_auc_scores]\n",
    "    test_predictions_final = np.average(test_predictions_all_folds, axis=0, weights=fold_weights)\n",
    "\n",
    "    # 平均驗證 AUC\n",
    "    avg_val_auc = np.mean(fold_auc_scores)\n",
    "    print(f\"Average AUC for {i+1}'th Dataset: {avg_val_auc:.4f}\")\n",
    "    validation_auc_scores.append(avg_val_auc)\n",
    "\n",
    "    # 儲存測試結果 CSV\n",
    "    df = pd.DataFrame(test_predictions_final, columns=['y_predict_proba'])\n",
    "    df.to_csv(f'./Competition_data/{dataset_names[i]}/y_predict.csv', index=False, header=True)\n",
    "\n",
    "# 儲存 AUC 分數為 CSV 文件\n",
    "auc_list = pd.DataFrame(validation_auc_scores, columns=[\"Validation AUC\"])\n",
    "auc_list.to_csv('./validation_auc_scores.csv', index_label='Dataset_Index', header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
