{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, NuSVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from imblearn.over_sampling import SMOTE, SMOTENC\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "from utils import save_predictions_to_csv, standardize_data, calculate_auc_score, compare_auc_scores\n",
    "from natsort import natsorted\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "- 選出數值以及類別型特徵\n",
    "- 對資料做 SMOTENC ，如果dataset只有數值型特徵就做 SMOTE\n",
    "- 數值特徵做 MinMaxScalar()\n",
    "- 類別特徵做 TargetEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names=[]\n",
    "X_trains=[]\n",
    "y_trains=[]\n",
    "X_tests=[]\n",
    "\n",
    "for folder_name in natsorted(os.listdir(\"./Competition_data\")):\n",
    "    dataset_names.append(folder_name)\n",
    "    X_trains.append(pd.read_csv(f\"./Competition_data/{folder_name}/X_train.csv\",header=0))\n",
    "    y_trains.append(pd.read_csv(f\"./Competition_data/{folder_name}/y_train.csv\",header=0))\n",
    "    X_tests.append(pd.read_csv(f\"./Competition_data/{folder_name}/X_test.csv\",header=0))\n",
    "\n",
    "def preprocess_data(X_train, y_train, X_test):\n",
    "\n",
    "    # 區分數值型和類別型特徵\n",
    "    numeric_features = X_train.select_dtypes(include=['float']).columns\n",
    "    categorical_features = X_train.select_dtypes(include=['int']).columns\n",
    "\n",
    "    # 將類別型特徵轉換為索引\n",
    "    categorical_feature_indices = [X_train.columns.get_loc(col) for col in categorical_features]\n",
    "\n",
    "    # 類別不平衡處理\n",
    "    if len(categorical_feature_indices) == 0:\n",
    "        smote = SMOTE(random_state=40)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        categorical_feature_indices_bool = [i in categorical_feature_indices for i in range(X_train.shape[1])]\n",
    "        smote_nc = SMOTENC(categorical_features=categorical_feature_indices_bool, random_state=41)\n",
    "        X_train, y_train = smote_nc.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # 數值型特徵標準化\n",
    "    numeric_transformer = MinMaxScaler()\n",
    "    X_train_numeric = numeric_transformer.fit_transform(X_train[numeric_features])\n",
    "    X_test_numeric = numeric_transformer.transform(X_test[numeric_features])\n",
    "\n",
    "    # 類別型特徵目標編碼\n",
    "    if len(categorical_features) > 0:\n",
    "        categorical_transformer = TargetEncoder(cols=categorical_features)\n",
    "        X_train_categorical = categorical_transformer.fit_transform(X_train[categorical_features], y_train)\n",
    "        X_test_categorical = categorical_transformer.transform(X_test[categorical_features])\n",
    "    else:\n",
    "        X_train_categorical = np.empty((X_train_numeric.shape[0], 0))\n",
    "        X_test_categorical = np.empty((X_test_numeric.shape[0], 0))\n",
    "\n",
    "    # 合併處理後的特徵\n",
    "    X_train = np.hstack((X_train_numeric, X_train_categorical))\n",
    "    X_test = np.hstack((X_test_numeric, X_test_categorical))\n",
    "\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "- 5-fold validation\n",
    "- 用 Bagging Boosting Staking 做 ensemble\n",
    "- Bagging -> randomforest, extratree, svm, nusvc, mlp\n",
    "- Boosting -> xgb, lightgbm, gbc, adaboost, catboost, hist_gb\n",
    "- Other -> easy_ensemble\n",
    "- Staking -> lineargression, BernoulliNB, GaussianNB, LinearDiscriminantAnalysis ; final_estimator = lg\n",
    "- final model -> mlp 用每個模型的 val 加權去預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation AUC for fold 1: 0.9468\n",
      "Validation AUC for fold 2: 0.9316\n",
      "Validation AUC for fold 3: 0.9242\n",
      "Validation AUC for fold 4: 0.9345\n",
      "Validation AUC for fold 5: 0.9549\n",
      "Average AUC for 1'th Dataset: 0.9384\n",
      "Validation AUC for fold 1: 0.9997\n",
      "Validation AUC for fold 2: 0.9991\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 1.0000\n",
      "Validation AUC for fold 5: 1.0000\n",
      "Average AUC for 2'th Dataset: 0.9998\n",
      "Validation AUC for fold 1: 0.7143\n",
      "Validation AUC for fold 2: 0.9388\n",
      "Validation AUC for fold 3: 0.8776\n",
      "Validation AUC for fold 4: 1.0000\n",
      "Validation AUC for fold 5: 1.0000\n",
      "Average AUC for 3'th Dataset: 0.9061\n",
      "Validation AUC for fold 1: 0.9912\n",
      "Validation AUC for fold 2: 0.9960\n",
      "Validation AUC for fold 3: 0.9965\n",
      "Validation AUC for fold 4: 0.9966\n",
      "Validation AUC for fold 5: 0.9989\n",
      "Average AUC for 4'th Dataset: 0.9958\n",
      "Validation AUC for fold 1: 0.9992\n",
      "Validation AUC for fold 2: 0.9997\n",
      "Validation AUC for fold 3: 0.9981\n",
      "Validation AUC for fold 4: 1.0000\n",
      "Validation AUC for fold 5: 0.9997\n",
      "Average AUC for 5'th Dataset: 0.9993\n",
      "Validation AUC for fold 1: 0.9952\n",
      "Validation AUC for fold 2: 0.9957\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 0.9957\n",
      "Validation AUC for fold 5: 0.9936\n",
      "Average AUC for 6'th Dataset: 0.9960\n",
      "Validation AUC for fold 1: 0.9998\n",
      "Validation AUC for fold 2: 1.0000\n",
      "Validation AUC for fold 3: 0.9995\n",
      "Validation AUC for fold 4: 0.9998\n",
      "Validation AUC for fold 5: 0.9988\n",
      "Average AUC for 7'th Dataset: 0.9996\n",
      "Validation AUC for fold 1: 0.9583\n",
      "Validation AUC for fold 2: 0.9117\n",
      "Validation AUC for fold 3: 0.9514\n",
      "Validation AUC for fold 4: 0.9514\n",
      "Validation AUC for fold 5: 0.9601\n",
      "Average AUC for 8'th Dataset: 0.9466\n",
      "Validation AUC for fold 1: 0.8533\n",
      "Validation AUC for fold 2: 0.9067\n",
      "Validation AUC for fold 3: 0.9333\n",
      "Validation AUC for fold 4: 0.9048\n",
      "Validation AUC for fold 5: 0.9238\n",
      "Average AUC for 9'th Dataset: 0.9044\n",
      "Validation AUC for fold 1: 0.9031\n",
      "Validation AUC for fold 2: 0.8347\n",
      "Validation AUC for fold 3: 0.8003\n",
      "Validation AUC for fold 4: 0.8667\n",
      "Validation AUC for fold 5: 0.8875\n",
      "Average AUC for 10'th Dataset: 0.8585\n",
      "Validation AUC for fold 1: 1.0000\n",
      "Validation AUC for fold 2: 0.9444\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 1.0000\n",
      "Validation AUC for fold 5: 0.7531\n",
      "Average AUC for 11'th Dataset: 0.9395\n",
      "Validation AUC for fold 1: 1.0000\n",
      "Validation AUC for fold 2: 1.0000\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 0.9793\n",
      "Validation AUC for fold 5: 0.9979\n",
      "Average AUC for 12'th Dataset: 0.9955\n",
      "Validation AUC for fold 1: 0.9734\n",
      "Validation AUC for fold 2: 0.9704\n",
      "Validation AUC for fold 3: 0.9734\n",
      "Validation AUC for fold 4: 0.9892\n",
      "Validation AUC for fold 5: 0.9831\n",
      "Average AUC for 13'th Dataset: 0.9779\n",
      "Validation AUC for fold 1: 1.0000\n",
      "Validation AUC for fold 2: 1.0000\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 1.0000\n",
      "Validation AUC for fold 5: 1.0000\n",
      "Average AUC for 14'th Dataset: 1.0000\n",
      "Validation AUC for fold 1: 0.9396\n",
      "Validation AUC for fold 2: 0.8688\n",
      "Validation AUC for fold 3: 0.9048\n",
      "Validation AUC for fold 4: 0.8788\n",
      "Validation AUC for fold 5: 0.8880\n",
      "Average AUC for 15'th Dataset: 0.8960\n",
      "Validation AUC for fold 1: 0.9997\n",
      "Validation AUC for fold 2: 0.9991\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 1.0000\n",
      "Validation AUC for fold 5: 1.0000\n",
      "Average AUC for 16'th Dataset: 0.9998\n",
      "Validation AUC for fold 1: 0.9260\n",
      "Validation AUC for fold 2: 0.9872\n",
      "Validation AUC for fold 3: 0.9679\n",
      "Validation AUC for fold 4: 0.9872\n",
      "Validation AUC for fold 5: 0.9872\n",
      "Average AUC for 17'th Dataset: 0.9711\n",
      "Validation AUC for fold 1: 1.0000\n",
      "Validation AUC for fold 2: 1.0000\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 1.0000\n",
      "Validation AUC for fold 5: 1.0000\n",
      "Average AUC for 18'th Dataset: 1.0000\n",
      "Validation AUC for fold 1: 1.0000\n",
      "Validation AUC for fold 2: 0.9930\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 0.9994\n",
      "Validation AUC for fold 5: 0.9965\n",
      "Average AUC for 19'th Dataset: 0.9978\n",
      "Validation AUC for fold 1: 0.9561\n",
      "Validation AUC for fold 2: 0.9883\n",
      "Validation AUC for fold 3: 0.9537\n",
      "Validation AUC for fold 4: 1.0000\n",
      "Validation AUC for fold 5: 0.9877\n",
      "Average AUC for 20'th Dataset: 0.9772\n",
      "Validation AUC for fold 1: 0.9771\n",
      "Validation AUC for fold 2: 0.9714\n",
      "Validation AUC for fold 3: 0.9673\n",
      "Validation AUC for fold 4: 0.9657\n",
      "Validation AUC for fold 5: 0.9951\n",
      "Average AUC for 21'th Dataset: 0.9753\n",
      "Validation AUC for fold 1: 0.9743\n",
      "Validation AUC for fold 2: 0.9853\n",
      "Validation AUC for fold 3: 0.9609\n",
      "Validation AUC for fold 4: 0.9648\n",
      "Validation AUC for fold 5: 0.9727\n",
      "Average AUC for 22'th Dataset: 0.9716\n",
      "Validation AUC for fold 1: 0.9498\n",
      "Validation AUC for fold 2: 0.9820\n",
      "Validation AUC for fold 3: 0.9487\n",
      "Validation AUC for fold 4: 0.9868\n",
      "Validation AUC for fold 5: 0.9578\n",
      "Average AUC for 23'th Dataset: 0.9650\n",
      "Validation AUC for fold 1: 0.8758\n",
      "Validation AUC for fold 2: 0.8721\n",
      "Validation AUC for fold 3: 0.8681\n",
      "Validation AUC for fold 4: 0.8770\n",
      "Validation AUC for fold 5: 0.8934\n",
      "Average AUC for 24'th Dataset: 0.8773\n",
      "Validation AUC for fold 1: 0.9967\n",
      "Validation AUC for fold 2: 1.0000\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 1.0000\n",
      "Validation AUC for fold 5: 1.0000\n",
      "Average AUC for 25'th Dataset: 0.9993\n",
      "Validation AUC for fold 1: 0.9017\n",
      "Validation AUC for fold 2: 0.9546\n",
      "Validation AUC for fold 3: 0.9244\n",
      "Validation AUC for fold 4: 0.9743\n",
      "Validation AUC for fold 5: 0.8874\n",
      "Average AUC for 26'th Dataset: 0.9285\n",
      "Validation AUC for fold 1: 1.0000\n",
      "Validation AUC for fold 2: 1.0000\n",
      "Validation AUC for fold 3: 1.0000\n",
      "Validation AUC for fold 4: 1.0000\n",
      "Validation AUC for fold 5: 1.0000\n",
      "Average AUC for 27'th Dataset: 1.0000\n",
      "Validation AUC for fold 1: 0.9772\n",
      "Validation AUC for fold 2: 0.8619\n",
      "Validation AUC for fold 3: 0.8928\n",
      "Validation AUC for fold 4: 0.9582\n",
      "Validation AUC for fold 5: 0.9551\n",
      "Average AUC for 28'th Dataset: 0.9290\n",
      "Validation AUC for fold 1: 0.9959\n",
      "Validation AUC for fold 2: 0.9469\n",
      "Validation AUC for fold 3: 0.9453\n",
      "Validation AUC for fold 4: 0.9567\n",
      "Validation AUC for fold 5: 0.9535\n",
      "Average AUC for 29'th Dataset: 0.9597\n",
      "Validation AUC for fold 1: 0.9187\n",
      "Validation AUC for fold 2: 0.9326\n",
      "Validation AUC for fold 3: 0.8578\n",
      "Validation AUC for fold 4: 0.9187\n",
      "Validation AUC for fold 5: 0.8699\n",
      "Average AUC for 30'th Dataset: 0.8995\n",
      "Validation AUC for fold 1: 0.9861\n",
      "Validation AUC for fold 2: 0.9861\n",
      "Validation AUC for fold 3: 0.9444\n",
      "Validation AUC for fold 4: 0.9848\n",
      "Validation AUC for fold 5: 0.9091\n",
      "Average AUC for 31'th Dataset: 0.9621\n",
      "Validation AUC for fold 1: 0.8768\n",
      "Validation AUC for fold 2: 0.9196\n",
      "Validation AUC for fold 3: 0.9000\n"
     ]
    }
   ],
   "source": [
    "validation_auc_scores = []\n",
    "\n",
    "for i in range(len(X_trains)):\n",
    "    X_train, y_train, X_test = preprocess_data(X_trains[i], y_trains[i].values.ravel(), X_tests[i])\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    test_predictions_all_folds = []\n",
    "    fold_auc_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold = X_train[train_idx, :]\n",
    "        y_train_fold = y_train[train_idx]\n",
    "        X_val_fold = X_train[val_idx, :]\n",
    "        y_val_fold = y_train[val_idx]\n",
    "\n",
    "        # 提前訓練基模型\n",
    "        rf = BaggingClassifier(estimator=RandomForestClassifier(), n_estimators=10, random_state=43, n_jobs=-1)\n",
    "        rf.fit(X_train_fold, y_train_fold)\n",
    "        rf_val_pred = rf.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        etc = BaggingClassifier(estimator=ExtraTreesClassifier(), n_estimators=10, random_state=44, n_jobs=-1) \n",
    "        etc.fit(X_train_fold, y_train_fold)\n",
    "        etc_val_pred = etc.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        svm = BaggingClassifier(estimator=SVC(), n_estimators=10, random_state=45, n_jobs=-1)\n",
    "        svm.fit(X_train_fold,y_train_fold)\n",
    "        svm_val_pred = svm.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        nusvc = BaggingClassifier(estimator=NuSVC(), n_estimators=10, random_state=46, n_jobs=-1)\n",
    "        nusvc.fit(X_train_fold, y_train_fold)\n",
    "        nusvc_val_pred = nusvc.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        mlp = BaggingClassifier(estimator=MLPClassifier(), n_estimators=10, random_state=47, n_jobs=-1)\n",
    "        mlp.fit(X_train_fold,y_train_fold)\n",
    "        mlp_val_pred = mlp.predict_proba(X_val_fold)[:,1]\n",
    "\n",
    "        xgb = XGBClassifier(n_estimators=200, max_depth=6, reg_alpha=0.1, reg_lambda=0.1,\n",
    "                             eval_metric='auc', early_stopping_rounds=5, random_state=48, n_jobs=-1)\n",
    "        xgb.fit(X_train_fold, y_train_fold, eval_set=[(X_val_fold, y_val_fold)],verbose = 0)\n",
    "        xgb_val_pred = xgb.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        lgbm = LGBMClassifier(n_estimators=200, max_depth=6, reg_alpha=0.1, reg_lambda=0.1, min_child_samples=5,\n",
    "                               min_split_gain=0.01, early_stopping_round=5, verbose=-1, random_state=49, n_jobs=-1)\n",
    "        lgbm.fit(X_train_fold, y_train_fold, eval_metric='auc', eval_set=[(X_val_fold, y_val_fold)])\n",
    "        lgbm_val_pred = lgbm.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        gbc = GradientBoostingClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=50)\n",
    "        gbc.fit(X_train_fold, y_train_fold)\n",
    "        gbc_val_pred = gbc.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        adaboost = AdaBoostClassifier(n_estimators=200, learning_rate=0.1, random_state=51)\n",
    "        adaboost.fit(X_train_fold, y_train_fold)\n",
    "        adaboost_val_pred = adaboost.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        catboost = CatBoostClassifier(iterations=200, learning_rate=0.1, depth=6, verbose=0, early_stopping_rounds=5, random_state=49)\n",
    "        catboost.fit(X_train_fold,y_train_fold)\n",
    "        catboost_val_pred = catboost.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        hist_gb = HistGradientBoostingClassifier(max_iter=200, max_depth=6, learning_rate=0.1, early_stopping=True, random_state=50)\n",
    "        hist_gb.fit(X_train_fold,y_train_fold)\n",
    "        hist_gb_val_pred = hist_gb.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        easy_ensemble = EasyEnsembleClassifier(n_estimators=10, n_jobs=-1, random_state=100)\n",
    "        easy_ensemble.fit(X_train_fold,y_train_fold)\n",
    "        easy_ensemble_val_pred = easy_ensemble.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        # 不需要提前訓練的模型\n",
    "        lg = LogisticRegression(max_iter=1000, random_state=52)\n",
    "        bnb = BernoulliNB()\n",
    "        gnb = GaussianNB()\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "        # 堆疊模型\n",
    "        stacking_model = StackingClassifier(\n",
    "            estimators=[('lg',lg),('bnb',bnb),('gnb',gnb),('lda',lda)],\n",
    "            final_estimator=BaggingClassifier(estimator=MLPClassifier(), n_estimators=10, random_state=53, n_jobs=-1),\n",
    "            stack_method='predict_proba',\n",
    "            cv=3,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        stacking_model.fit(X_train_fold, y_train_fold)\n",
    "        stk_val_pred = stacking_model.predict_proba(X_val_fold)[:, 1]\n",
    "\n",
    "        rf_auc = roc_auc_score(y_val_fold, rf_val_pred)\n",
    "        etc_auc = roc_auc_score(y_val_fold, etc_val_pred)\n",
    "        svm_auc = roc_auc_score(y_val_fold, svm_val_pred)\n",
    "        nusvc_auc = roc_auc_score(y_val_fold, nusvc_val_pred)\n",
    "        mlp_auc = roc_auc_score(y_val_fold, mlp_val_pred)\n",
    "        xgb_auc = roc_auc_score(y_val_fold, xgb_val_pred)\n",
    "        lgbm_auc = roc_auc_score(y_val_fold, lgbm_val_pred)\n",
    "        gbc_auc = roc_auc_score(y_val_fold, gbc_val_pred)\n",
    "        adaboost_auc = roc_auc_score(y_val_fold, adaboost_val_pred)\n",
    "        catboost_auc = roc_auc_score(y_val_fold, catboost_val_pred)\n",
    "        hist_gb_auc = roc_auc_score(y_val_fold, hist_gb_val_pred)\n",
    "        easy_ensemble_auc = roc_auc_score(y_val_fold, easy_ensemble_val_pred)\n",
    "        stk_auc = roc_auc_score(y_val_fold, stk_val_pred)\n",
    "\n",
    "        model_aucs = [rf_auc, etc_auc, svm_auc, nusvc_auc, mlp_auc, \n",
    "                      xgb_auc, lgbm_auc, gbc_auc, adaboost_auc, catboost_auc, hist_gb_auc,\n",
    "                       easy_ensemble_auc, stk_auc]\n",
    "        \n",
    "        normalized_weights = [auc / sum(model_aucs) for auc in model_aucs]\n",
    "\n",
    "        # 組合基模型預測概率\n",
    "        meta_features = np.column_stack([rf_val_pred, etc_val_pred, svm_val_pred, nusvc_val_pred, mlp_val_pred,\n",
    "                                          xgb_val_pred, lgbm_val_pred, gbc_val_pred, adaboost_val_pred, catboost_val_pred, hist_gb_val_pred, \n",
    "                                          easy_ensemble_val_pred, stk_val_pred])\n",
    "        weighted_meta_features = np.average(meta_features, axis=1, weights=normalized_weights)\n",
    "        meta_model = BaggingClassifier(estimator=LogisticRegression(), n_estimators=10, random_state=54, n_jobs=-1)\n",
    "        meta_model.fit(weighted_meta_features.reshape(-1,1), y_val_fold)\n",
    "\n",
    "        # 驗證集預測\n",
    "        y_val_pred = meta_model.predict_proba(weighted_meta_features.reshape(-1,1))[:, 1]\n",
    "        val_auc = roc_auc_score(y_val_fold, y_val_pred)\n",
    "        print(f\"Validation AUC for fold {fold + 1}: {val_auc:.4f}\")\n",
    "        fold_auc_scores.append(val_auc)\n",
    "\n",
    "        # 測試集預測\n",
    "        rf_test_pred = rf.predict_proba(X_test)[:, 1]\n",
    "        etc_test_pred = etc.predict_proba(X_test)[:, 1]\n",
    "        svm_test_pred = svm.predict_proba(X_test)[:, 1]\n",
    "        nusvc_test_pred = nusvc.predict_proba(X_test)[:, 1]\n",
    "        mlp_test_pred = mlp.predict_proba(X_test)[:, 1]\n",
    "        xgb_test_pred = xgb.predict_proba(X_test)[:, 1]\n",
    "        lgbm_test_pred = lgbm.predict_proba(X_test)[:, 1]\n",
    "        gbc_test_pred = gbc.predict_proba(X_test)[:, 1]\n",
    "        adaboost_test_pred = adaboost.predict_proba(X_test)[:, 1]\n",
    "        catboost_test_pred = catboost.predict_proba(X_test)[:, 1]\n",
    "        hist_gb_test_pred = hist_gb.predict_proba(X_test)[:, 1]\n",
    "        easy_ensemble_test_pred = easy_ensemble_test_pred(X_test)[:, 1]\n",
    "        stk_test_pred = stacking_model.predict_proba(X_test)[:, 1]\n",
    "        test_meta_features = np.column_stack([rf_test_pred, etc_test_pred, svm_test_pred, nusvc_test_pred, mlp_test_pred, xgb_test_pred,\n",
    "                                               lgbm_test_pred, gbc_test_pred, adaboost_test_pred, catboost_test_pred, hist_gb_test_pred,\n",
    "                                               easy_ensemble_test_pred, stk_test_pred])\n",
    "        \n",
    "        weighted_test_feature = np.average(test_meta_features, axis=1, weights=normalized_weights)\n",
    "        y_test_pred = meta_model.predict_proba(test_meta_features.reshape(-1,1))[:, 1]\n",
    "        test_predictions_all_folds.append(y_test_pred)\n",
    "\n",
    "    # 計算加權測試集預測\n",
    "    total_auc = sum(fold_auc_scores)\n",
    "    fold_weights = [auc / total_auc for auc in fold_auc_scores]\n",
    "    test_predictions_final = np.average(test_predictions_all_folds, axis=0, weights=fold_weights)\n",
    "\n",
    "    # 計算平均驗證 AUC\n",
    "    avg_val_auc = np.mean(fold_auc_scores)\n",
    "    print(f\"Average AUC for {i+1}'th Dataset: {avg_val_auc:.4f}\")\n",
    "    validation_auc_scores.append(avg_val_auc)\n",
    "\n",
    "    # 儲存測試結果 CSV\n",
    "    df = pd.DataFrame(test_predictions_final, columns=['y_predict_proba'])\n",
    "    df.to_csv(f'./Competition_data/{dataset_names[i]}/y_predict.csv', index=False, header=True)\n",
    "\n",
    "# 儲存 AUC 分數為 CSV 文件\n",
    "auc_list = pd.DataFrame(validation_auc_scores, columns=[\"Validation AUC\"])\n",
    "auc_list.to_csv('./validation_auc_scores.csv', index_label='Dataset_Index', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
