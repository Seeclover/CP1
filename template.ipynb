{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read All Dataset CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset_1\n",
      "X_train shape: (444, 20)\n",
      "y_train shape: (444, 1)\n",
      "X_test shape: (296, 20)\n",
      "------------------------------\n",
      "Dataset: Dataset_10\n",
      "X_train shape: (467, 11)\n",
      "y_train shape: (467, 1)\n",
      "X_test shape: (312, 11)\n",
      "------------------------------\n",
      "Dataset: Dataset_11\n",
      "X_train shape: (58, 62)\n",
      "y_train shape: (58, 1)\n",
      "X_test shape: (39, 62)\n",
      "------------------------------\n",
      "Dataset: Dataset_12\n",
      "X_train shape: (154, 5)\n",
      "y_train shape: (154, 1)\n",
      "X_test shape: (104, 5)\n",
      "------------------------------\n",
      "Dataset: Dataset_13\n",
      "X_train shape: (181, 54)\n",
      "y_train shape: (181, 1)\n",
      "X_test shape: (122, 54)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataset_names=[]\n",
    "X_trains=[]\n",
    "y_trains=[]\n",
    "X_tests=[]\n",
    "for folder_name in os.listdir(\"./Competition_data\"):\n",
    "    # print(folder_name)\n",
    "    dataset_names.append(folder_name)\n",
    "    X_trains.append(pd.read_csv(f\"./Competition_data/{folder_name}/X_train.csv\",header=0))\n",
    "    y_trains.append(pd.read_csv(f\"./Competition_data/{folder_name}/y_train.csv\",header=0))\n",
    "    X_tests.append(pd.read_csv(f\"./Competition_data/{folder_name}/X_test.csv\",header=0))\n",
    "\n",
    "\n",
    "for i in range(min(5, len(dataset_names))):\n",
    "    print(f\"Dataset: {dataset_names[i]}\")\n",
    "    print(f\"X_train shape: {X_trains[i].shape}\")\n",
    "    print(f\"y_train shape: {y_trains[i].shape}\")\n",
    "    print(f\"X_test shape: {X_tests[i].shape}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n",
    "# Summary of datasets loaded\n",
    "def summarize_datasets(dataset_names, X_trains, y_trains, X_tests):\n",
    "    \"\"\"\n",
    "    Print a summary of the loaded datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    dataset_names: List of dataset names\n",
    "    X_trains: List of training feature matrices\n",
    "    y_trains: List of training label arrays\n",
    "    X_tests: List of testing feature matrices\n",
    "    \"\"\"\n",
    "    #print(f\"Total number of datasets loaded: {len(dataset_names)}\\n\")\n",
    "    #for i in range(len(dataset_names)):\n",
    "        #print(f\"Dataset: {dataset_names[i]}\")\n",
    "        #print(f\"X_train shape: {X_trains[i].shape}\")\n",
    "        #print(f\"y_train shape: {y_trains[i].shape}\")\n",
    "        #print(f\"X_test shape: {X_tests[i].shape}\")\n",
    "        #print(\"-\" * 30)\n",
    "\n",
    "summarize_datasets(dataset_names, X_trains, y_trains, X_tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare AUC score function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_auc(model1_auc_scores, model2_auc_scores, dataset_names):\n",
    "    \"\"\"\n",
    "    Compare AUC scores of two models across datasets and calculate the difference.\n",
    "\n",
    "    Parameters:\n",
    "    model1_auc_scores (list): AUC scores of the first model for each dataset.\n",
    "    model2_auc_scores (list): AUC scores of the second model for each dataset.\n",
    "    dataset_names (list): List of dataset names.\n",
    "\n",
    "    Returns:\n",
    "    differences (dict): A dictionary containing dataset names as keys and AUC differences as values.\n",
    "    \"\"\"\n",
    "    differences = {}\n",
    "    \n",
    "    for i in range(len(dataset_names)):\n",
    "        diff = model1_auc_scores[i] - model2_auc_scores[i]\n",
    "        differences[dataset_names[i]] = diff\n",
    "        print(f\"Dataset: {dataset_names[i]} - AUC Difference: {diff:.4f} (Model 1 - Model 2)\")\n",
    "    \n",
    "    return differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split & build Model\n",
    "You can select an appropriate model and perform corresponding hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of AUC Scores:\n",
      "Dataset_1: 0.6343\n",
      "Dataset_10: 0.7294\n",
      "Dataset_11: 0.4571\n",
      "Dataset_12: 0.8500\n",
      "Dataset_13: 0.9167\n",
      "Dataset_14: 0.9483\n",
      "Dataset_15: 0.6258\n",
      "Dataset_16: 0.9696\n",
      "Dataset_17: 0.9000\n",
      "Dataset_18: 0.7500\n",
      "Dataset_19: 0.9766\n",
      "Dataset_2: 0.9696\n",
      "Dataset_20: 0.9273\n",
      "Dataset_21: 0.8397\n",
      "Dataset_22: 0.7974\n",
      "Dataset_23: 0.9020\n",
      "Dataset_24: 0.6349\n",
      "Dataset_25: 0.7963\n",
      "Dataset_26: 0.7769\n",
      "Dataset_27: 1.0000\n",
      "Dataset_28: 0.8194\n",
      "Dataset_29: 0.8735\n",
      "Dataset_3: 0.5625\n",
      "Dataset_30: 0.7291\n",
      "Dataset_31: 0.6061\n",
      "Dataset_32: 0.6807\n",
      "Dataset_33: 0.9834\n",
      "Dataset_34: 0.7557\n",
      "Dataset_35: 0.8054\n",
      "Dataset_36: 0.9176\n",
      "Dataset_37: 0.8704\n",
      "Dataset_38: 0.6620\n",
      "Dataset_39: 0.9547\n",
      "Dataset_4: 0.5694\n",
      "Dataset_40: 0.8054\n",
      "Dataset_41: 0.9235\n",
      "Dataset_42: 1.0000\n",
      "Dataset_43: 0.6807\n",
      "Dataset_44: 1.0000\n",
      "Dataset_45: 1.0000\n",
      "Dataset_46: 0.9000\n",
      "Dataset_47: 0.4464\n",
      "Dataset_48: 0.8937\n",
      "Dataset_49: 0.9809\n",
      "Dataset_5: 0.7467\n",
      "Dataset_6: 0.9546\n",
      "Dataset_7: 0.7751\n",
      "Dataset_8: 0.6909\n",
      "Dataset_9: 0.8822\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "\n",
    "models = []\n",
    "auc_scores = []  # 用于存储每个数据集的 AUC 分数\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    # Split the dataset into training and testing sets\n",
    "    tmp_X_train, tmp_X_test, tmp_y_train, tmp_y_test = train_test_split(X_trains[i], y_trains[i], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train the KNN classifier\n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(tmp_X_train, tmp_y_train.squeeze())\n",
    "    \n",
    "    # Predict the probabilities for the test set\n",
    "    tmp_y_prob = model.predict_proba(tmp_X_test)[:, 1]\n",
    "    \n",
    "    # Calculate the AUC score\n",
    "    auc = roc_auc_score(tmp_y_test, tmp_y_prob)\n",
    "    \n",
    "    # Store the model and AUC score\n",
    "    models.append(model)\n",
    "    auc_scores.append(auc)\n",
    "\n",
    "# Optional: Print a summary of all AUC scores\n",
    "print(\"\\nSummary of AUC Scores:\")\n",
    "for i, auc in enumerate(auc_scores):\n",
    "    print(f\"{dataset_names[i]}: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicts=[]\n",
    "for i in range(len(dataset_names)):\n",
    "    y_predict_proba=models[i].predict_proba(X_tests[i])[:, 1]\n",
    "    df = pd.DataFrame(y_predict_proba, columns=['y_predict_proba'])\n",
    "    y_predicts.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,dataset_name in enumerate(dataset_names):\n",
    "    df=y_predicts[idx]\n",
    "    df.to_csv(f'./Competition_data/{dataset_name}/y_predict.csv', index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try other different models here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Logistic Regression AUC Scores:\n",
      "Dataset_1: 0.7313\n",
      "Dataset_10: 0.8033\n",
      "Dataset_11: 0.3714\n",
      "Dataset_12: 0.6667\n",
      "Dataset_13: 0.9300\n",
      "Dataset_14: 0.9900\n",
      "Dataset_15: 0.6608\n",
      "Dataset_16: 1.0000\n",
      "Dataset_17: 0.9556\n",
      "Dataset_18: 1.0000\n",
      "Dataset_19: 0.9938\n",
      "Dataset_2: 1.0000\n",
      "Dataset_20: 0.9455\n",
      "Dataset_21: 0.9476\n",
      "Dataset_22: 0.7059\n",
      "Dataset_23: 0.9096\n",
      "Dataset_24: 0.6365\n",
      "Dataset_25: 0.5062\n",
      "Dataset_26: 0.7885\n",
      "Dataset_27: 1.0000\n",
      "Dataset_28: 0.8409\n",
      "Dataset_29: 0.8865\n",
      "Dataset_3: 0.8125\n",
      "Dataset_30: 0.8195\n",
      "Dataset_31: 0.7727\n",
      "Dataset_32: 0.8295\n",
      "Dataset_33: 0.9980\n",
      "Dataset_34: 0.8614\n",
      "Dataset_35: 0.8306\n",
      "Dataset_36: 1.0000\n",
      "Dataset_37: 0.8951\n",
      "Dataset_38: 0.8550\n",
      "Dataset_39: 0.9919\n",
      "Dataset_4: 0.3684\n",
      "Dataset_40: 0.8306\n",
      "Dataset_41: 0.9342\n",
      "Dataset_42: 1.0000\n",
      "Dataset_43: 0.8295\n",
      "Dataset_44: 1.0000\n",
      "Dataset_45: 1.0000\n",
      "Dataset_46: 0.9365\n",
      "Dataset_47: 0.5000\n",
      "Dataset_48: 0.9943\n",
      "Dataset_49: 0.9766\n",
      "Dataset_5: 0.9233\n",
      "Dataset_6: 0.9327\n",
      "Dataset_7: 0.9808\n",
      "Dataset_8: 0.9382\n",
      "Dataset_9: 0.9038\n"
     ]
    }
   ],
   "source": [
    "#Logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize lists to store models and AUC scores for Logistic Regression\n",
    "logistic_models = []\n",
    "logistic_auc_scores = []\n",
    "logistic_y_predicts = []  # Store the predictions for each dataset\n",
    "\n",
    "# Loop through each dataset and train a Logistic Regression model\n",
    "for i in range(len(dataset_names)):\n",
    "    # Split the dataset into training and testing sets\n",
    "    tmp_X_train, tmp_X_test, tmp_y_train, tmp_y_test = train_test_split(X_trains[i], y_trains[i], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train the Logistic Regression model\n",
    "    logistic_model = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence\n",
    "    logistic_model.fit(tmp_X_train, tmp_y_train.squeeze())\n",
    "    \n",
    "    # Predict the probabilities for the test set\n",
    "    tmp_y_prob = logistic_model.predict_proba(tmp_X_test)[:, 1]\n",
    "    \n",
    "    # Calculate the AUC score\n",
    "    auc = roc_auc_score(tmp_y_test, tmp_y_prob)\n",
    "    \n",
    "    # Store the model and AUC score\n",
    "    logistic_models.append(logistic_model)\n",
    "    logistic_auc_scores.append(auc)\n",
    "    \n",
    "    # Store predictions\n",
    "    logistic_y_predicts.append(pd.DataFrame(tmp_y_prob, columns=['y_predict_proba']))\n",
    "\n",
    "# Optional: Print a summary of all Logistic Regression AUC scores\n",
    "print(\"\\nSummary of Logistic Regression AUC Scores:\")\n",
    "for i, auc in enumerate(logistic_auc_scores):\n",
    "    print(f\"{dataset_names[i]}: {auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, dataset_name in enumerate(dataset_names):\n",
    "    df = logistic_y_predicts[idx]\n",
    "    df.to_csv(f'./Competition_data/{dataset_name}/y_predict.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of SVM AUC Scores:\n",
      "Dataset_1: 0.6235\n",
      "Dataset_10: 0.7534\n",
      "Dataset_11: 0.4857\n",
      "Dataset_12: 0.8667\n",
      "Dataset_13: 0.9433\n",
      "Dataset_14: 0.9800\n",
      "Dataset_15: 0.6608\n",
      "Dataset_16: 0.9938\n",
      "Dataset_17: 0.9037\n",
      "Dataset_18: 1.0000\n",
      "Dataset_19: 0.8236\n",
      "Dataset_2: 0.9938\n",
      "Dataset_20: 0.8485\n",
      "Dataset_21: 0.9289\n",
      "Dataset_22: 0.7582\n",
      "Dataset_23: 0.9167\n",
      "Dataset_24: 0.6139\n",
      "Dataset_25: 0.8889\n",
      "Dataset_26: 0.7808\n",
      "Dataset_27: 1.0000\n",
      "Dataset_28: 0.5876\n",
      "Dataset_29: 0.8108\n",
      "Dataset_3: 0.3125\n",
      "Dataset_30: 0.8026\n",
      "Dataset_31: 0.6667\n",
      "Dataset_32: 0.7286\n",
      "Dataset_33: 0.9766\n",
      "Dataset_34: 0.8114\n",
      "Dataset_35: 0.7043\n",
      "Dataset_36: 0.9927\n",
      "Dataset_37: 0.8395\n",
      "Dataset_38: 0.7460\n",
      "Dataset_39: 0.9806\n",
      "Dataset_4: 0.5337\n",
      "Dataset_40: 0.7043\n",
      "Dataset_41: 0.8943\n",
      "Dataset_42: 0.6434\n",
      "Dataset_43: 0.7286\n",
      "Dataset_44: 1.0000\n",
      "Dataset_45: 0.9333\n",
      "Dataset_46: 0.9333\n",
      "Dataset_47: 0.5357\n",
      "Dataset_48: 0.9867\n",
      "Dataset_49: 0.9604\n",
      "Dataset_5: 0.8100\n",
      "Dataset_6: 0.9551\n",
      "Dataset_7: 0.9659\n",
      "Dataset_8: 0.8836\n",
      "Dataset_9: 0.7885\n"
     ]
    }
   ],
   "source": [
    "#SVM(no kernel)\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_models = []\n",
    "svm_auc_scores = []\n",
    "svm_y_predicts = []  \n",
    "\n",
    "# Loop through each dataset and train an SVM model\n",
    "for i in range(len(dataset_names)):\n",
    "    # Split the dataset into training and testing sets\n",
    "    tmp_X_train, tmp_X_test, tmp_y_train, tmp_y_test = train_test_split(X_trains[i], y_trains[i], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train the SVM model with probability estimation enabled\n",
    "    svm_model = SVC(kernel='poly', degree=2, probability=True)  # Using RBF kernel with probability estimates\n",
    "    svm_model.fit(tmp_X_train, tmp_y_train.squeeze())\n",
    "    \n",
    "    # Predict the probabilities for the test set\n",
    "    tmp_y_prob = svm_model.predict_proba(tmp_X_test)[:, 1]\n",
    "    \n",
    "    # Calculate the AUC score\n",
    "    auc = roc_auc_score(tmp_y_test, tmp_y_prob)\n",
    "    \n",
    "    # Store the model and AUC score\n",
    "    svm_models.append(svm_model)\n",
    "    svm_auc_scores.append(auc)\n",
    "    \n",
    "    # Store predictions\n",
    "    svm_y_predicts.append(pd.DataFrame(tmp_y_prob, columns=['y_predict_proba']))\n",
    "\n",
    "# Optional: Print a summary of all SVM AUC scores\n",
    "print(\"\\nSummary of SVM AUC Scores:\")\n",
    "for i, auc in enumerate(svm_auc_scores):\n",
    "    print(f\"{dataset_names[i]}: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Neural Network AUC Scores:\n",
      "Dataset_1: 0.7449\n",
      "Dataset_10: 0.7436\n",
      "Dataset_11: 0.3143\n",
      "Dataset_12: 0.9762\n",
      "Dataset_13: 0.9500\n",
      "Dataset_14: 0.9900\n",
      "Dataset_15: 0.6925\n",
      "Dataset_16: 0.9995\n",
      "Dataset_17: 0.9407\n",
      "Dataset_18: 1.0000\n",
      "Dataset_19: 0.9956\n",
      "Dataset_2: 0.9995\n",
      "Dataset_20: 0.9212\n",
      "Dataset_21: 0.9382\n",
      "Dataset_22: 0.7386\n",
      "Dataset_23: 0.9184\n",
      "Dataset_24: 0.6016\n",
      "Dataset_25: 0.9383\n",
      "Dataset_26: 0.7731\n",
      "Dataset_27: 1.0000\n",
      "Dataset_28: 0.7866\n",
      "Dataset_29: 0.9200\n",
      "Dataset_3: 0.7917\n",
      "Dataset_30: 0.6937\n",
      "Dataset_31: 0.8030\n",
      "Dataset_32: 0.8012\n",
      "Dataset_33: 1.0000\n",
      "Dataset_34: 0.8429\n",
      "Dataset_35: 0.8371\n",
      "Dataset_36: 0.9194\n",
      "Dataset_37: 0.8210\n",
      "Dataset_38: 0.7480\n",
      "Dataset_39: 0.9913\n",
      "Dataset_4: 0.6276\n",
      "Dataset_40: 0.8371\n",
      "Dataset_41: 0.9398\n",
      "Dataset_42: 0.9650\n",
      "Dataset_43: 0.8012\n",
      "Dataset_44: 1.0000\n",
      "Dataset_45: 1.0000\n",
      "Dataset_46: 0.9111\n",
      "Dataset_47: 0.6071\n",
      "Dataset_48: 0.9412\n",
      "Dataset_49: 0.9693\n",
      "Dataset_5: 0.8900\n",
      "Dataset_6: 0.9510\n",
      "Dataset_7: 0.9787\n",
      "Dataset_8: 0.7891\n",
      "Dataset_9: 0.8702\n"
     ]
    }
   ],
   "source": [
    "#MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize lists to store models, AUC scores, and predictions for Neural Network\n",
    "nn_models = []\n",
    "nn_auc_scores = []\n",
    "nn_y_predicts = []\n",
    "\n",
    "# Loop through each dataset and train a Neural Network model\n",
    "for i in range(len(dataset_names)):\n",
    "    # Split the dataset into training and testing sets\n",
    "    tmp_X_train, tmp_X_test, tmp_y_train, tmp_y_test = train_test_split(X_trains[i], y_trains[i], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Standardize the features (important for neural networks)\n",
    "    scaler = StandardScaler()\n",
    "    tmp_X_train = scaler.fit_transform(tmp_X_train)\n",
    "    tmp_X_test = scaler.transform(tmp_X_test)\n",
    "    \n",
    "    # Initialize and train the Neural Network model\n",
    "    nn_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, learning_rate_init=0.01, random_state=42)\n",
    "    nn_model.fit(tmp_X_train, tmp_y_train.squeeze())\n",
    "    \n",
    "    # Predict the probabilities for the test set\n",
    "    tmp_y_prob = nn_model.predict_proba(tmp_X_test)[:, 1]\n",
    "    \n",
    "    # Calculate the AUC score\n",
    "    auc = roc_auc_score(tmp_y_test, tmp_y_prob)\n",
    "    \n",
    "    # Store the model and AUC score\n",
    "    nn_models.append(nn_model)\n",
    "    nn_auc_scores.append(auc)\n",
    "    \n",
    "    # Store predictions\n",
    "    nn_y_predicts.append(pd.DataFrame(tmp_y_prob, columns=['y_predict_proba']))\n",
    "\n",
    "# Optional: Print a summary of all Neural Network AUC scores\n",
    "print(\"\\nSummary of Neural Network AUC Scores:\")\n",
    "for i, auc in enumerate(nn_auc_scores):\n",
    "    print(f\"{dataset_names[i]}: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Random Forest AUC Scores:\n",
      "Dataset_1: 0.8284\n",
      "Dataset_10: 0.7744\n",
      "Dataset_11: 0.5143\n",
      "Dataset_12: 1.0000\n",
      "Dataset_13: 0.9367\n",
      "Dataset_14: 1.0000\n",
      "Dataset_15: 0.7412\n",
      "Dataset_16: 0.9995\n",
      "Dataset_17: 0.9185\n",
      "Dataset_18: 1.0000\n",
      "Dataset_19: 0.9907\n",
      "Dataset_2: 0.9995\n",
      "Dataset_20: 0.9273\n",
      "Dataset_21: 0.9878\n",
      "Dataset_22: 0.8627\n",
      "Dataset_23: 0.9375\n",
      "Dataset_24: 0.6088\n",
      "Dataset_25: 0.9938\n",
      "Dataset_26: 0.8038\n",
      "Dataset_27: 1.0000\n",
      "Dataset_28: 0.8519\n",
      "Dataset_29: 0.9514\n",
      "Dataset_3: 0.8750\n",
      "Dataset_30: 0.8192\n",
      "Dataset_31: 0.8106\n",
      "Dataset_32: 0.7224\n",
      "Dataset_33: 1.0000\n",
      "Dataset_34: 0.8657\n",
      "Dataset_35: 0.8500\n",
      "Dataset_36: 0.9780\n",
      "Dataset_37: 0.8765\n",
      "Dataset_38: 0.7865\n",
      "Dataset_39: 0.9951\n",
      "Dataset_4: 0.6255\n",
      "Dataset_40: 0.8500\n",
      "Dataset_41: 0.9972\n",
      "Dataset_42: 1.0000\n",
      "Dataset_43: 0.7224\n",
      "Dataset_44: 1.0000\n",
      "Dataset_45: 1.0000\n",
      "Dataset_46: 0.9683\n",
      "Dataset_47: 0.5000\n",
      "Dataset_48: 1.0000\n",
      "Dataset_49: 0.9858\n",
      "Dataset_5: 0.5800\n",
      "Dataset_6: 0.9689\n",
      "Dataset_7: 0.9606\n",
      "Dataset_8: 0.9509\n",
      "Dataset_9: 0.8702\n"
     ]
    }
   ],
   "source": [
    "#Random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize lists to store models, AUC scores, and predictions for Random Forest\n",
    "rf_models = []\n",
    "rf_auc_scores = []\n",
    "rf_y_predicts = []\n",
    "\n",
    "# Loop through each dataset and train a Random Forest model\n",
    "for i in range(len(dataset_names)):\n",
    "    # Split the dataset into training and testing sets\n",
    "    tmp_X_train, tmp_X_test, tmp_y_train, tmp_y_test = train_test_split(X_trains[i], y_trains[i], test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize and train the Random Forest model\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)  # You can increase n_estimators for better performance\n",
    "    rf_model.fit(tmp_X_train, tmp_y_train.squeeze())\n",
    "    \n",
    "    # Predict the probabilities for the test set\n",
    "    tmp_y_prob = rf_model.predict_proba(tmp_X_test)[:, 1]\n",
    "    \n",
    "    # Calculate the AUC score\n",
    "    auc = roc_auc_score(tmp_y_test, tmp_y_prob)\n",
    "    \n",
    "    # Store the model and AUC score\n",
    "    rf_models.append(rf_model)\n",
    "    rf_auc_scores.append(auc)\n",
    "    \n",
    "    # Store predictions\n",
    "    rf_y_predicts.append(pd.DataFrame(tmp_y_prob, columns=['y_predict_proba']))\n",
    "\n",
    "# Optional: Print a summary of all Random Forest AUC scores\n",
    "print(\"\\nSummary of Random Forest AUC Scores:\")\n",
    "for i, auc in enumerate(rf_auc_scores):\n",
    "    print(f\"{dataset_names[i]}: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, dataset_name in enumerate(dataset_names):\n",
    "    df = rf_y_predicts[idx]\n",
    "    df.to_csv(f'./Competition_data/{dataset_name}/y_predict.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Dataset_1 - AUC Difference: 0.0970 (Model 1 - Model 2)\n",
      "Dataset: Dataset_10 - AUC Difference: -0.0289 (Model 1 - Model 2)\n",
      "Dataset: Dataset_11 - AUC Difference: 0.1429 (Model 1 - Model 2)\n",
      "Dataset: Dataset_12 - AUC Difference: 0.3333 (Model 1 - Model 2)\n",
      "Dataset: Dataset_13 - AUC Difference: 0.0067 (Model 1 - Model 2)\n",
      "Dataset: Dataset_14 - AUC Difference: 0.0100 (Model 1 - Model 2)\n",
      "Dataset: Dataset_15 - AUC Difference: 0.0804 (Model 1 - Model 2)\n",
      "Dataset: Dataset_16 - AUC Difference: -0.0005 (Model 1 - Model 2)\n",
      "Dataset: Dataset_17 - AUC Difference: -0.0370 (Model 1 - Model 2)\n",
      "Dataset: Dataset_18 - AUC Difference: 0.0000 (Model 1 - Model 2)\n",
      "Dataset: Dataset_19 - AUC Difference: -0.0031 (Model 1 - Model 2)\n",
      "Dataset: Dataset_2 - AUC Difference: -0.0005 (Model 1 - Model 2)\n",
      "Dataset: Dataset_20 - AUC Difference: -0.0182 (Model 1 - Model 2)\n",
      "Dataset: Dataset_21 - AUC Difference: 0.0402 (Model 1 - Model 2)\n",
      "Dataset: Dataset_22 - AUC Difference: 0.1569 (Model 1 - Model 2)\n",
      "Dataset: Dataset_23 - AUC Difference: 0.0279 (Model 1 - Model 2)\n",
      "Dataset: Dataset_24 - AUC Difference: -0.0277 (Model 1 - Model 2)\n",
      "Dataset: Dataset_25 - AUC Difference: 0.4877 (Model 1 - Model 2)\n",
      "Dataset: Dataset_26 - AUC Difference: 0.0154 (Model 1 - Model 2)\n",
      "Dataset: Dataset_27 - AUC Difference: 0.0000 (Model 1 - Model 2)\n",
      "Dataset: Dataset_28 - AUC Difference: 0.0110 (Model 1 - Model 2)\n",
      "Dataset: Dataset_29 - AUC Difference: 0.0649 (Model 1 - Model 2)\n",
      "Dataset: Dataset_3 - AUC Difference: 0.0625 (Model 1 - Model 2)\n",
      "Dataset: Dataset_30 - AUC Difference: -0.0003 (Model 1 - Model 2)\n",
      "Dataset: Dataset_31 - AUC Difference: 0.0379 (Model 1 - Model 2)\n",
      "Dataset: Dataset_32 - AUC Difference: -0.1070 (Model 1 - Model 2)\n",
      "Dataset: Dataset_33 - AUC Difference: 0.0020 (Model 1 - Model 2)\n",
      "Dataset: Dataset_34 - AUC Difference: 0.0043 (Model 1 - Model 2)\n",
      "Dataset: Dataset_35 - AUC Difference: 0.0194 (Model 1 - Model 2)\n",
      "Dataset: Dataset_36 - AUC Difference: -0.0220 (Model 1 - Model 2)\n",
      "Dataset: Dataset_37 - AUC Difference: -0.0185 (Model 1 - Model 2)\n",
      "Dataset: Dataset_38 - AUC Difference: -0.0685 (Model 1 - Model 2)\n",
      "Dataset: Dataset_39 - AUC Difference: 0.0032 (Model 1 - Model 2)\n",
      "Dataset: Dataset_4 - AUC Difference: 0.2571 (Model 1 - Model 2)\n",
      "Dataset: Dataset_40 - AUC Difference: 0.0194 (Model 1 - Model 2)\n",
      "Dataset: Dataset_41 - AUC Difference: 0.0630 (Model 1 - Model 2)\n",
      "Dataset: Dataset_42 - AUC Difference: 0.0000 (Model 1 - Model 2)\n",
      "Dataset: Dataset_43 - AUC Difference: -0.1070 (Model 1 - Model 2)\n",
      "Dataset: Dataset_44 - AUC Difference: 0.0000 (Model 1 - Model 2)\n",
      "Dataset: Dataset_45 - AUC Difference: 0.0000 (Model 1 - Model 2)\n",
      "Dataset: Dataset_46 - AUC Difference: 0.0317 (Model 1 - Model 2)\n",
      "Dataset: Dataset_47 - AUC Difference: 0.0000 (Model 1 - Model 2)\n",
      "Dataset: Dataset_48 - AUC Difference: 0.0057 (Model 1 - Model 2)\n",
      "Dataset: Dataset_49 - AUC Difference: 0.0092 (Model 1 - Model 2)\n",
      "Dataset: Dataset_5 - AUC Difference: -0.3433 (Model 1 - Model 2)\n",
      "Dataset: Dataset_6 - AUC Difference: 0.0362 (Model 1 - Model 2)\n",
      "Dataset: Dataset_7 - AUC Difference: -0.0203 (Model 1 - Model 2)\n",
      "Dataset: Dataset_8 - AUC Difference: 0.0127 (Model 1 - Model 2)\n",
      "Dataset: Dataset_9 - AUC Difference: -0.0337 (Model 1 - Model 2)\n",
      "{'Dataset_1': 0.09701492537313439, 'Dataset_10': -0.028904428904429014, 'Dataset_11': 0.1428571428571429, 'Dataset_12': 0.33333333333333326, 'Dataset_13': 0.006666666666666599, 'Dataset_14': 0.010000000000000009, 'Dataset_15': 0.08041666666666658, 'Dataset_16': -0.00047846889952141147, 'Dataset_17': -0.03703703703703709, 'Dataset_18': 0.0, 'Dataset_19': -0.0030864197530864335, 'Dataset_2': -0.00047846889952141147, 'Dataset_20': -0.018181818181818188, 'Dataset_21': 0.04020979020979021, 'Dataset_22': 0.1568627450980392, 'Dataset_23': 0.027925531914893664, 'Dataset_24': -0.027701778385772813, 'Dataset_25': 0.48765432098765427, 'Dataset_26': 0.015384615384615441, 'Dataset_27': 0.0, 'Dataset_28': 0.011021505376344054, 'Dataset_29': 0.06486486486486465, 'Dataset_3': 0.0625, 'Dataset_30': -0.00033921302578021617, 'Dataset_31': 0.037878787878787845, 'Dataset_32': -0.10703918722786654, 'Dataset_33': 0.001953125, 'Dataset_34': 0.004285714285714337, 'Dataset_35': 0.01935483870967758, 'Dataset_36': -0.0219780219780219, 'Dataset_37': -0.01851851851851849, 'Dataset_38': -0.0685, 'Dataset_39': 0.003182870370370239, 'Dataset_4': 0.2571428571428572, 'Dataset_40': 0.01935483870967758, 'Dataset_41': 0.06302131603336425, 'Dataset_42': 0.0, 'Dataset_43': -0.10703918722786654, 'Dataset_44': 0.0, 'Dataset_45': 0.0, 'Dataset_46': 0.031746031746031744, 'Dataset_47': 0.0, 'Dataset_48': 0.005692599620493399, 'Dataset_49': 0.009228740936057855, 'Dataset_5': -0.3433333333333334, 'Dataset_6': 0.0362244897959183, 'Dataset_7': -0.02025586353944564, 'Dataset_8': 0.012727272727272698, 'Dataset_9': -0.033653846153846145}\n"
     ]
    }
   ],
   "source": [
    "a = compare_auc_scores(rf_auc_scores, logistic_auc_scores, dataset_names)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
